---
title: "Replication Methods for Two-phase Sampling"
output: 
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: true
    highlighted: default 
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: no
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Replication Methods for Two-phase Sampling}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  \usepackage[utf8]{inputenc}
bibliography: references.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE, warning=FALSE, echo=FALSE}
library(dplyr) # For data manipulation
library(survey) # For complex survey analysis
library(srvyr) # For complex survey analysis with dplyr syntax
library(svrep)
```

This vignette provides an overview of two-phase sampling and how the 'svrep' package can be used to estimate sampling variances for estimators that are commonly-used in two-phase sampling. Readers who are already familiar with two-phase sampling and its applications are encouraged to skip to Section 3 of this vignette for a description of variance estimators and their implementation in the 'svrep' package.

# Two-phase Sampling vs. Multistage Sampling

Two-phase sampling (also known as "double sampling") is a common feature in surveys. In a two-phase sample, a large first-phase sample is selected, and a smaller second-phase sample is selected from the first-phase sample. Multistage cluster sampling is a special case of two-phase sampling, where a second-phase sample of secondary sampling units (SSUs) are selected from a first-phase sample of primary sampling units (PSUs). In the specific case of multistage sampling, the second-phase sampling of SSUs must sample at least one SSU from within each PSU and must sample independently across PSUs (in other words, each PSU is treated as a stratum in second-phase sampling). Two-phase sampling in general does not have these restrictions: the second-phase sample design can be arbitrary, and some primary sampling units might not appear at all in the second-phase sample. The flexibility of two-phase sampling can be quite valuable, for reasons we discuss below.

# Applications of Two-Phase Sampling

Broadly speaking, two-phase sampling tends to be used either to reduce costs of collecting high-quality data or to reduce sampling variance of estimates.

## Application 1: Lowering Survey Costs

Below, we discuss two common examples of where two-phase sampling is used to reduce the cost of gathering representative data for a survey.

### Example 1: Online Survey Panels

Much survey research nowadays is conducted using online panels, which are collections of people who individually responded to an initial recruitment request and agreed to periodically complete online survey questionnaires, typically in exchange for an incentive such as \$10 per completed questionnaire. The highest-quality online panels are formed using a probability sample, where the individuals recruited to join the online panel were selected using probability sampling. High-quality online panels may be expensive to create and maintain, but they allow the cost of recruiting a nationally representative sample to be split across many surveys rather than incurred repeatedly the many surveys.

Any given survey conducted using an online panel is necessarily a two-phase sample, where the panel recruitment represents the first phase of sampling and the process of requesting panelists to participate in a specific survey represents the second phase of sampling. Often, the recruitment sampling is quite complex (e.g., three-stage stratified cluster sampling), but the sampling of panelists for a given survey is conducted using simple random sampling or stratified simple random sampling from the list of panelists.

### Example 2: Nonresponse Follow-up

When we experience nonresponse in a survey, this poses two problems. First, we end up with a smaller realized sample size than we intended, resulting in higher variance for our estimates. Second, we are at risk of nonresponse bias, caused by unknown and potentially large differences in the characteristics of respondents and nonrespondents. To learn what differs between respondents and nonrespondents, and thus adjust for this using weighting, we can randomly subsample nonrespondents to the survey and expend special effort and money to obtain a 100\% response rate from this subsample as part of a "nonresponse follow-up survey." 

The set of original respondents and the randomly-selected nonresponse follow-up subsample represents collectively represent a second-phase sample selected from our original first-phase sample. The advantage of this approach is that every person's probability of participating in the survey is known and controlled, and thus nonresponse bias can be completely eliminated using weighting. This approach is much less expensive than simply spending more effort and money on every single sampled person in order to obtain a 100\% response rate from a one-phase survey.

## Application 2: Reducing Sampling Variances

Two-phase sampling is useful when some variables are expensive to measure and thus can only be measured in a small sample, but some closely-correlated variables can be measured inexpensively through a larger survey. For example, highly-accurate blood tests for Covid-19 infection are expensive and can only be measured using a small survey, whereas self-reported Covid-19 infection can be inexpensively measured using a large questionnaire-based survey. **By drawing our small sample from the larger sample and using the auxiliary data from the large sample to help select the small sample and produce estimates from it, we can produce estimates using the small sample which are more precise than if we had simply drawn a small, single-phase simple random sample.**

The information from the first-phase sample is useful for both design and analysis of the second-phase sample. From a design standpoint, information collected in the first-phase sample can be used to stratify units or assign unequal sampling probabilities for the second-phase sampling, which can result in more precise estimates relative to using simple random sampling. From an analysis standpoint, the information collected in the first-phase sample can also be used to improve estimators, by using raking, post-stratification, or generalized regression (GREG) to calibrate the small second-phase sample to the large first-phase sample.

# Replicate Variance Estimation with the 'svrep' package

In this vignette, we'll show how to use the generalized bootstrap to estimate sampling variances for estimates based on two-phase sample designs. Other types of replication such as the jackknife or balanced repeated replication (BRR) can theoretically be used, but the 'svrep' package only implements the generalized bootstrap method, because it is relatively simple and is applicable to a much larger variety of sample designs than the jackknife or BRR.

## Overview of the Generalized Bootstrap

Most every variance estimator for a population total estimated using sampling weights $\hat{Y}=\sum_{i=1}^{n}(y_i/\pi_i)$ can be written as a quadratic form. That is, we can write a variance estimator $v(\hat{Y})$ as $v(\hat{Y})=\sum_{i=1}^{n}\sum_{i=1}^{n} \sigma_{ij}(w_iy_i)(w_jy_j)$, for some set of values $\sigma_{ij},i,j \in \{1,\dots,n\}$. In matrix notation, we can write $v(\hat{Y})=\breve{y}^{\prime}\Sigma\breve{y}$, where $\Sigma$ is the symmetric, positive semi-definite matrix of dimension $n \times n$, with element $ij$ equal to $\sigma_{ij}$, and $\breve{y}$ is a vector whose $i$-th element is $w_iy_i$.

As noted by @fay1984, if we can write a variance estimator as a quadratic form, then we can always make a replication estimator out of it. One method for doing this is the generalized survey bootstrap, which essentially “mimics” a target variance estimator for population totals, where the target variance estimator is appropriate to the particular sampling design and can be written down as a quadratic form. The generalized bootstrap method generates a set of replicate weights such that, on average, the bootstrap variance for an estimated total matches the variance estimate one would get from using the target variance estimator.

For an overview of the generalized survey bootstrap and its use in the 'svrep' package, the reader is encouraged to read the 'svrep' package vignette titled "Bootstrap Methods for Surveys". For a thorough overview of the generalized survey bootstrap and its theory, @beaumont2012 provide a clear introduction and several useful suggestions for its implementation in practice.

When using the generalized bootstrap, the difficult part of the variance estimation process is simply identifying the quadratic form. Once the quadratic form has been written down, it is easy to create replicate weights using the generalized bootstrap.

Fortunately, the 'svrep' package can automatically identify the appropriate quadratic form to use for variance estimators for many single-phase and two-phase sample designs. The user simply needs to supply the necessary data, describe the survey design, and select target variance estimators for each phase of sampling.

## Creating Example Data

In the example below, we create a two-phase survey design:

  - The first phase is a stratified multistage sample, where the first stage sample of PSUs was selected using unequal probability sampling without replacement (PPSWOR) and the second stage sample was selected using simple random sampling without replacement (SRSWOR). 
  
  - The second phase sample is a simple random sample without replacement from the first phase sample.

This type of design would be fairly typical for a survey conducted on an online panel, where the panel recruitment uses a complex design but the sampling of panelists for a given survey uses simple random sampling of panelists.

The particular dataset we'll use comes from the Public Libraries Survey (PLS), an annual survey of public libraries in the U.S, with data from FY2020.

```{r}
data('library_multistage_sample', package = 'svrep')

# Load first-phase sample
  twophase_sample <- library_multistage_sample

# Select second-phase sample
  set.seed(2022)
  
  twophase_sample[['SECOND_PHASE_SELECTION']] <- sampling::srswor(
    n = 100,
    N = nrow(twophase_sample)
  ) |> as.logical()
```

## Describing the Two-phase Survey Design

Next, we use the 'survey' package's function `twophase()` to describe the sample design at each phase, in terms of stratification, clustering, probabilities, and population sizes. Note that we use a `list()` for most arguments, where the first element of the list describes the first phase of sampling, and the second element of the list describes the second phase of sampling.

```{r}
# Declare survey design
  twophase_design <- twophase(
    method = "full",
    data = twophase_sample,
    # Identify the subset of first-phase elements
    # which were selected into the second-phase sample
    subset = ~ SECOND_PHASE_SELECTION,
    # Describe clusters, probabilities, and population sizes
    # at each phase of sampling
    id = list(~ PSU_ID + SSU_ID,
              ~ 1),
    probs = list(~ PSU_SAMPLING_PROB + SSU_SAMPLING_PROB,
                 NULL),
    fpc = list(~ PSU_POP_SIZE + SSU_POP_SIZE,
               NULL)
  )
```

## Creating Generalized Bootstrap Replicates

Once the two-phase design has been described, we can use the `as_gen_boot_design()` function to create generalized bootstrap replicate weights. This requires us to specify the desired number of replicates and the target variance estimator for each phase of sampling.

```{r, warning=FALSE}
# Obtain a generalized bootstrap replicates
# based on 
#   - The phase 1 estimator is the usual variance estimator
#     for stratified multistage simple random sampling
#   - The phase 2 estimator is the usual variance estimator
#     for single-stage simple random sampling

twophase_gen_boot <- as_gen_boot_design(
  design = twophase_design,
  variance_estimator = list(
    "Phase 1" = "Stratified Multistage SRS",
    "Phase 2" = "Ultimate Cluster"
  ),
  replicates = 1000
)
```

The result is a replicate survey design object which can be used for estimation with the usual functions from the 'survey' and 'srvyr' packages.

```{r}
twophase_gen_boot |> svymean(x = ~ LIBRARIA)
```

When using `as_gen_boot_design()` for two-phase designs, it's useful to know that you will often see a warning message about needing to approximate the first-phase variance estimator's quadratic form.

```{r}
twophase_boot_design <- as_gen_boot_design(
  design = twophase_design,
  variance_estimator = list(
    "Phase 1" = "Stratified Multistage SRS",
    "Phase 2" = "Ultimate Cluster"
  )
)
```

As you can see from the output above, the function emitted a warning message. The generalized bootstrap works by mimicking a variance estimator but requires that variance estimator to be represented as a positive semidefinite qudratic form. In two-phase designs, however, it is often the case that the usual variance estimator cannot be represented exactly as a positive semidefinite quadratic form. In such cases, @beaumont2012 suggest using an approximation of the actual quadratic form matrix by the most similar positive semidefinite matrix. This approximation will in general never lead to an underestimation of variance, and @beaumont2012 argue that this should only produce a small overestimate of variance in practice. The documentation for the function `make_twophase_quad_form()` provides additional details of this approximation and an explanation of why variance estimators for two-phase designs sometimes fail to be positive semidefinite.

## Estimating the Sampling Variance Using a Quadratic Form

For the two-phase sample, we can get the quadratic form matrix of a two-phase variance estimator using the function `twophase_quad_form()`. For the argument `variance_estimator`, we supply a list with two elements, where the first element is the name of the variance estimator to use for the first phase of sampling, and the second element is the name of the variance estimator to use for the second phase of sampling.

```{r}
# Obtain a quadratic form for a two-phase variance estimator, where:
#   - The phase 1 estimator is the usual variance estimator
#     for stratified multistage simple random sampling
#   - The phase 2 estimator is the usual variance estimator
#     for single-stage simple random sampling

twophase_quad_form_matrix <- get_design_quad_form(
  design = twophase_design,
  variance_estimator = list(
    "Phase 1" = "Stratified Multistage SRS",
    "Phase 2" = "Ultimate Cluster"
  )
)
```

Note that the result is a matrix with the number of rows and columns equal to the second-phase sample size.

```{r}
# Inspect the dimensions of the matrix
dim(twophase_quad_form_matrix)

# Preview the first five rows and columns
twophase_quad_form_matrix[1:5,1:5]
```

The details on how this quadratic form is determined can be found in the section of this vignette titled "Variance of the Double Expansion Estimator", and in the help page for the function `make_twophase_quad_form()`. ^[The 'survey' package itself will actually attempt to automatically determine the quadratic form matrix of the Horvitz-Thompson-type variance estimator for two-phase designs, and that is what it uses for variance estimation. The Horvitz-Thompson-type quadratic form determined by the 'survey' package can be accessed from a two-phase survey design object (say, `my_twophase_design`) using the code `my_twophase_design$dcheck$full`. However, there are some bugs with this functionality in practice, and so it is instead recommended to use the 'svrep' function `get_design_quad_form()`. The 'svrep' function `get_design_quad_form()` currently has clearer documentation and more thorough unit testing compared to the equivalent functions in the 'survey' package: `survey:::twophaseDcheck()` and `survey:::Dcheck_multi_subset()`]

This allows us to estimate the variance of a total estimated using two-phase sampling. To illustrate, we'll estimate the total number of full-time librarians employed at public library systems in the United States in FY2020.

```{r}
# Extract weights (accounting for both phases of sampling)
wts <- weights(twophase_design, type = "sampling")

# Extract variable of interest
y <- twophase_design$phase1$sample$variables |>
    pull("LIBRARIA")
y[is.na(y)] <- 0

# Weight the variable of interest
wtd_y <- y * wts

# Estimate population total
estimated_total <- sum(wtd_y)

# Estimate its sampling variance
estimated_var <- as.numeric(
  t(wtd_y) %*% twophase_quad_form_matrix %*% wtd_y
)
std_error <- sqrt(estimated_var)

# Print the estimates
print(estimated_total)
print(std_error)
```

This gives us an estimate of `r estimated_total |> round() |> format(big.mark=",",scientific=FALSE)` librarians, with a standard error of `r std_error |> round() |> format(big.mark=",",scientific=FALSE)`. As we might expect, this standard error is larger than the estimated standard error we would get if we had used the full phase-one sample for the estimate.

```{r}
twophase_design$phase1$full |>
  svytotal(x = ~ LIBRARIA, na.rm = TRUE)
```

# Design-based Estimators for Two-phase Sampling

In the section below, we first describe the double expansion estimator (DEE) which produces unbiased estimates for two-phase samples, using only information about the sampling design in both phases. Next, we describe calibration estimators which adjust the weights from the double-expansion estimator so that sampling variances can be reduced using information from the first-phase sample. We'll examine both the theoretical sampling variance of each estimator as well as approaches for estimating variance using replication methods.

The interested reader is encouraged to consult chapter 9.3 of @sarndalModelAssistedSurvey1992 or chapter 12 of @lohrSamplingDesignAnalysis2022 for a more detailed discussion of two-phase sampling.

## Notation

We use the following notation to denote each sample and its size.

### Notation for Samples and Sample Size

$$
\begin{aligned}
s_a &: \text{The set of units in the first-phase sample} \\
s_b &: \text{The set of units in the second-phase sample} \\
& \space \space \space \text{Note that }s_1 \text{ is a subset of } s_2 \\
n_a &: \text{The number of units in }s_1 \\
n_b &: \text{The number of units in }s_2 \\
\end{aligned}
$$

### Notation for Probabilities and Weights

We use the following notation to denote the **inclusion probability** of each unit, for each phase:

$$
\begin{aligned}
\pi^{(a)}_{i} &: \text{The probability unit }i \text{ is included in } s_a \\
\pi^{(b|s_a)}_{i} &: \text{The conditional probability unit }i \text{ is included in } s_b, \\
& \text{ given the realized first-phase sample }s_a \\
\pi_i &: \text{The } \textbf{unconditional} \text{ probability unit }i \text{ is included in }s_b \\
\end{aligned}
$$

In practice, the probability $\pi_i$ is prohibitively difficult to calculate, because it requires us to figure out $\pi^{(b|s_a)}_{i}$ for every possible first-phase sample $s_a$, not just the particular $s_a$ that we actually selected. So instead, we define the useful quantity $\pi^{*}$, which depends only on the particular first-phase sample $s_a$ that we actually selected.

$$
\pi_i^{*} := \pi^{(b|s_a)}_{i} \times \pi^{(a)}_{i}
$$

For variance estimation, it's also necessary to consider the **joint inclusion probability** (sometimes referred to as "second order probability"), which is simply the probability that a pair of units $i$ and $j$ are both included in a sample.

$$
\begin{aligned}
\pi^{(a)}_{ij} &: \text{The probability units }i \text{ and } j \text{ are both included in } s_a \\
\pi^{(b|s_a)}_{ij} &: \text{The conditional probability units }i \text{ and } j \text{ are both included in } s_b, \\
& \text{ given the realized first-phase sample }s_a \\
\end{aligned}
$$

We also define the quantity $\pi^{*}_{ij}$ similar to $\pi^{*}_i$.

$$
\pi_{ij}^{*} := \pi^{(b|s_a)}_{ij} \times \pi^{(a)}_{ij}
$$

The probabilities and the $\pi_{i}^{*}$ values are used to define sampling weights for the survey.

$$
\begin{aligned}
w^{(a)}_i &:= 1/\pi^{(a)}_i \\
w^{(b|s_a)}_i &:= 1/\pi^{(b|s_a)}_{i} \\
w^{*}_i &:= 1/\pi^{*}_i = w^{(b|s_a)}_i \times w^{(a)}_i
\end{aligned}
$$

## The Double Expansion Estimator

Suppose we wish to estimate a population total $Y$, using observed values $y_i$ in our second-phase sample, $s_b$. @sarndalModelAssistedSurvey1992 show that we can produce an unbiased estimate of $Y$ using the second-phase sample $s_b$, as follows:

$$
\begin{aligned}
\hat{Y}^{(b)} &= \sum_{i=1}^{n_{(b)}} w^{*}_i \times y_i  \\
&= \sum_{i=1}^{n_{(b)}} w^{(b|s_a)}_i \times w^{(a)}_i \times y_i
\end{aligned}
$$

This estimator has been dubbed the "double expansion estimator", using the sampling jargon that refers to weighting a sample value $y_i$ as "expanding" $y_i$ from the sample to the population. The name "double expansion" is used because the weight $w^{*}_i$ can be thought of as first using the weight $w^{(b|s_a)}_i$ to "expand" the quantity $y_i$ and then using the weight $w^{(a)}_i$ to expand the quantity $w^{(b|s_a)}_i \times y_i$.

### Variance of the Double Expansion Estimator

The sampling variance of the double expansion estimator is the sum of two different components.

$$
\begin{aligned}
V\left(\hat{Y}^{(b)}\right) &= V\left(\hat{Y}^{(a)}\right)+E\left(V\left[\hat{Y}^{(b)} \mid s_a \right]\right) \\
\\
\text{where: }& \hat{Y}^{(a)} = \sum_{i=1}^{n_{(a)}} w^{(a)}_i \times y_i \\
\text{and }& V\left[\hat{Y}^{(b)} \mid s_a \right] \text{ is the variance of } \hat{Y}^{(b)} \\
&\text{ across all samples } s_b \\
&\text{ drawn from a given } s_a
\end{aligned}
$$

The first component is the variance of the estimate $\hat{Y}^{(a)}$ that we would obtain if we used the entire first-phase sample $s_a$ for our estimate, rather than using the subset $s_b$. 

The second component is the additional variance caused by using the subset $s_b$ instead of $s_a$. It is equal to the expected value (across all samples $s_a$) of the conditional variance of $\hat{Y}^{(b)}$ across all samples $s_b$ (conditioning on a given first-phase sample $s_a$).

#### Estimating the Variance of the Double Expansion Estimator

Both variance components can be estimated using only the values $y_i$ observed in $s_b$. For the second component, we simply estimate $V\left[\hat{Y}^{(b)} \mid s_a \right]$, which is an unbiased estimate for its expectation, $E\left(V\left[\hat{Y}^{(b)} \mid s_a \right]\right)$. 

Thus, our variance estimate for the double expansion estimator takes the following form:

$$
\hat{V}\left(\hat{Y}^{(b)}\right) = \hat{V}\left[\hat{Y}^{(a)} \right] + \hat{V}\left[\hat{Y}^{(b)} \mid s_a \right]
$$

##### Estimating the second-phase variance component 

For estimating $\hat{V}\left[\hat{Y}^{(b)} \mid s_a \right]$, we simply choose a variance estimator for the second-phase design, taking the first-phase sample as a given. We assume that this variance estimator can be written as a quadratic form.

$$
\begin{aligned}
\hat{V}\left[\hat{Y}^{(b)} \mid s_a \right] &= \sum_{i=1}^{n_b} \sum_{i=1}^{n_b} \sigma^{(b)}_{ij} (w^{*}_i y_i) (w^{*}_j y_j) \\
\end{aligned}
$$

For the Horvitz-Thompson estimator, for instance, we would use $\sigma^{(b)}_{ij}=\left(1 - \frac{\pi^{b|s_a}_i\pi^{b|s_a}_j}{\pi^{b|s_a}_{ij}}\right)$.

This quadratic form can also be written in matrix notation:

$$
\begin{aligned}
\hat{V}\left[\hat{Y}^{(b)} \mid s_a \right] &= {(W^{*} y)}^{\prime} \Sigma_b {(W^{*} y)} \\
\text{where }& \Sigma_b \text{ is an } n_b \times n_b \text{ symmetric matrix} \\
& \text{ with entry } ij \text{ equal to } \sigma^{(b)}_{ij} \\
\text{and } & W^{*} \text{ is the } n_b \times n_b \text{ diagonal matrix} \\
& \text{ with entry } ii \text{ equal to } w^{*}_i  \\
& y \text{ is the } n_b \times 1 \text{ vector of values} \\
& \text{for the variable of interest}
\end{aligned}
$$

##### Estimating the first-phase variance component

Estimating the first variance component, $V\left(\hat{Y}^{(a)}\right)$, is only slightly trickier. First, we need to choose a variance estimator appropriate to the first-phase design, which we would use if we had $y_i$ observed for the entire sample $s_a$. We'll denote that variance estimator $\tilde{V}\left[\hat{Y}^{(a)}\right]$.

$$
\begin{aligned}
\tilde{V}\left[\hat{Y}^{(a)} \right] &= \sum_{i=1}^{n_a} \sum_{i=1}^{n_a} \sigma^{(a)}_{ij} (w^{(a)}_i y_i) (w^{(a)}_i y_j) \\
\end{aligned}
$$

In matrix notation, we can write:

$$
\begin{aligned}
\tilde{V}\left[\hat{Y}^{(a)} \right] &= {(W^{(a)} y)}^{\prime} (\Sigma_{a} ) {(W^{(a)} y)} \\
\text{where }& \Sigma_{a} \text{ is an } n_a \times n_a \text{ symmetric matrix} \\
& \text{ with entry } ij \text{ equal to } \sigma_{ij} \\
\text{and } & W^{(a)} \text{ is the } n_a \times n_a \text{ diagonal matrix} \\
& \text{ with entry } ii \text{ equal to } w^{(a)}_i 
\end{aligned}
$$

However, since we're working with the subsample $s_b$ instead of $s_a$, we need to estimate $\tilde{V}\left[\hat{Y}^{(a)} \right]$ using only the data from $s_b$. We can use the second-phase joint inclusion probabilities $\pi^{(b \mid s_a)}_{ij}$ to produce an unbiased estimate of $\tilde{V}\left[\hat{Y}^{(a)} \right]$ using only the data from $s_b$.

$$
\begin{aligned}
\hat{V}\left[\hat{Y}^{(a)} \right] &=  \sum_{i=1}^{n_b} \sum_{i=1}^{n_b} \frac{1}{\pi^{(b \mid s_a)}_{ij}} \sigma^{(a)}_{ij} (w^{(a)}_i y_i) (w^{(a)}_i y_j) \\
\end{aligned}
$$

We can also write this in matrix notation:

$$
\begin{aligned}
\hat{V}\left[\hat{Y}^{(a)} \right] &= {(W^{(a)} y)}^{\prime} (\Sigma_{a^{\prime}} \circ D_b ) {(W^{(a)} y)} \\
\text{where }& \Sigma_{a^{\prime}} \text{ is an } n_b \times n_b \text{ symmetric matrix} \\
& \text{ with entry } ij \text{ equal to } \sigma_{ij} \\
\text{and } & W^{(a)} \text{ is the } n_b \times n_b \text{ diagonal matrix} \\
& \text{ with entry } ii \text{ equal to } w^{(a)}_i 
\\
\text{ and }& D_b \text{ is an } n_b \times n_b \text{ symmetric matrix} \\
& \text{ with entry } ij \text{ equal to } \frac{1}{\pi^{(b \mid s_a)}_{ij}}\\
\end{aligned}
$$

As a sidenote, that matrix $D_b$ is very likely the source of any warning messages you'll see about a two-phase variance estimator not being positive semidefinite. [^2]

[^2]: When a two-phase variance estimator is not positive semidefinite, the culprit is usually the matrix $D_b$. The matrix $D_b$ is frequently not positive semidefinite and as a result causes the whole quadratic form not to be positive semidefinite. The matrices $\Sigma_{a}$ and $\Sigma_{b}$ are positive semidefinite for the usual single-phase variance estimators for most single-phase designs in practice, and so $\Sigma_{a^{\prime}}$ is too (since it is a principal submatrix of $\Sigma_{a}$). But when $D_b$ isn't also positive semidefinite, then $(\Sigma_{a^{\prime}} \circ D_b)$ generally won't be either. For one simple example of a $D_b$ which is not positive semidefinite, consider a simple random sample without replacement of size $n=2$ from a population of $N=4$. The matrix $D_b= \bigl( \begin{smallmatrix}(1/2)^{-1} & (1/6)^{-1} \\ (1/6)^{-1} & (1/2)^{-1} \end{smallmatrix}\bigr) =\bigl( \begin{smallmatrix}2 & 6\\ 6 & 2\end{smallmatrix}\bigr)$ is not positive semidefinite, since it has eigenvalues $8$ and $-4$.

##### Combining the two estimated variance components

Putting the two estimated variance components together, we thus obtain the following unbiased variance estimator for the double expansion estimator.

$$
\begin{aligned}
\hat{V}\left(\hat{Y}^{(b)}\right) &= \hat{V}\left(\hat{Y}^{(a)}\right)+\hat{V}\left[\hat{Y}^{(b)} \mid s_a \right] \\
&= \sum_{i=1}^{n_b} \sum_{i=1}^{n_b} \frac{1}{\pi^{(b \mid s_a)}_{ij}} \sigma^{(a)}_{ij} (w^{(a)}_i y_i) (w^{(a)}_i y_j) \\
&+ \sum_{i=1}^{n_b} \sum_{i=1}^{n_b} \sigma^{(b)}_{ij} (w^{*}_i y_i) (w^{*}_j y_j) \\
\end{aligned}
$$

In matrix notation, we can write this as follows:

$$
\begin{aligned}
\hat{V}\left(\hat{Y}^{(b)}\right) &= \hat{V}\left(\hat{Y}^{(a)}\right)+\hat{V}\left[\hat{Y}^{(b)} \mid s_a \right] \\
&= {(W^{(a)} y)}^{\prime} (\Sigma_{a^{\prime}} \circ D_b ) {(W^{(a)} y)} \\
&+ {(W^{*} y)}^{\prime} \Sigma_b {(W^{*} y)} \\
\end{aligned}
$$

Because quadratic forms are additive and because $W^{*}=W^{(a)}W^{(b \mid s_a)}$, we can more compactly write the estimator as follows:

$$
\begin{aligned}
\hat{V}\left(\hat{Y}^{(b)}\right) &= (W^{*}y)^{\prime} \Sigma_{ab} (W^{*}y) \\
\text{where } & \\
\Sigma_{ab} &=  {W^{(b)}}^{-1} (\Sigma_{a^{\prime}} \circ D_b ) {W^{(b)}}^{-1} + \Sigma_b \\
\text{where } & W^{(b)} \text{ is the } n_b \times n_b \text{ diagonal matrix} \\
& \text{ with entry } ii \text{ equal to } w^{(b \mid s_a)}_i 
\end{aligned}
$$

In the 'svrep' package, $\Sigma_{ab}$ can be constructed with the inputs $\Sigma_{a^{\prime}}$, $\Sigma_b$, and $(1/D_b)$, using the function `make_twophase_quad_form()`.

<details>
<summary>
Click to show/hide example of using `make_twophase_quad_form()`
</summary>

```{r}
set.seed(2022)
y <- rnorm(n = 100)

# Select first phase sample, SRS without replacement
  phase_1_sample_indicators <- sampling::srswor(n = 50, N = 100) |>
    as.logical()
  
  phase_1_sample <- y[phase_1_sample_indicators]
  
# Make variance estimator for first-phase variance component
  Sigma_a <- make_quad_form_matrix(
    variance_estimator = "Ultimate Cluster",
    cluster_ids = as.matrix(1:50),
    strata_ids = rep(1, times = 50) |> as.matrix(),
    strata_pop_sizes = rep(100, times = 50) |> as.matrix()
  )

# Select second stage sample, SRS without replacment
  phase_2_sample_indicators <- sampling::srswor(n = 5, N = 50) |>
    as.logical()
  
  phase_2_sample <- phase_1_sample[phase_2_sample_indicators]
  
# Estimate two-phase variance
  Sigma_a_prime <- Sigma_a[phase_2_sample_indicators,
                           phase_2_sample_indicators]
  
  phase_2_joint_probs <- outer(rep(5/50, times = 5),
                               rep(4/49, times = 5))
  diag(phase_2_joint_probs) <- rep(5/50, times = 5)

  Sigma_b <- make_quad_form_matrix(
    variance_estimator = "Ultimate Cluster",
    cluster_ids = as.matrix(1:5),
    strata_ids = rep(1, times = 5) |> as.matrix(),
    strata_pop_sizes = rep(50, times = 5) |> as.matrix()
  )
  
  sigma_ab <- make_twophase_quad_form(
    sigma_1 = Sigma_a_prime,
    sigma_2 = Sigma_b,
    phase_2_joint_probs = phase_2_joint_probs
  )
  
  wts <- rep(
    (50/100)^(-1) * (5/50)^(-1),
    times = 5
  )
  W_star <- diag(wts)
  
  W_star_y <- W_star %*% phase_2_sample
  t(W_star_y) %*% sigma_ab %*% (W_star_y)
  
# Since both phases are SRS without replacement,
# variance estimate for a total should be similar to the following
  5 * var(W_star_y)

```

</details>

<br>

The matrix notation is useful for understanding replication methods of variance estimation for two-phase samples. Any unbiased replication variance estimator for two-phase samples should generate each set of adjustment factors so that the sets of replicate weights have expectation $\mathbf{1}_{n_b}$ and variance-covariance matrix $\boldsymbol{\Sigma}_{ab}$. 

The generalized bootstrap does this by generating draws from a multivariate normal distribution with those parameters. For some specific combinations of simple first-phase and second-phase designs, there are jackknife and BRR methods which have been developed to accomplish this same goal (see @lohrSamplingDesignAnalysis2022 for some examples). The generalized bootstrap however is much easier to use for the complex designs actually encountered in most settings and also enjoys other advantages ^[See the vignette "Bootstrap Methods for Surveys"].

## Calibration Estimators

### Variance of the Calibration Estimator

# Ensuring the Variance Estimator is Positive Semidefinite

If you've made it this far in the vignette, then you're probably now well-aware that variance estimators for two-phase designs are often not the positive semidefinite quadratic form we'd like them to be. Instead, they're usually close to but not quite a positive semidefinite quadratic form, owing to the difficulty of estimating the first-phase variance component.[^4]

[^4]: Recall that the first-phase variance component is estimated by an estimator of an estimator. To be precise, $\hat{V}\left[\hat{Y}^{(a)} \right]$ is an estimate using the second-phase sample $s_b$ of the variance estimator $\tilde{V}\left[\hat{Y}^{(a)}\right]$ based on $s_a$ that we would have used if we had observed values of $y$ for the entire first-phase sample.

One solution for handling a quadratic form matrix $\Sigma_{ab}$ which is not positive semidefinite is to approximate it by $\tilde{\Sigma}_{ab} = \Gamma \Lambda^{*} \Gamma^{\prime}$, where $\Gamma$ is a matrix of eigenvalues of $\Sigma_{ab}$, $\Lambda$ is the diagonal matrix of eigenvalues of $\Sigma_{ab}$, and $\Lambda^{*}$ is an updated version of $\Lambda$ where negative eigenvalues have been replaced by $0$. This solution was first suggested in the context of two-phase sampling by @langlet2008 and is discussed by @beaumont2012 as a general-purpose solution for implementing the generalized bootstrap when the target variance estimator it's mimicking isn't positive semidefinite. @beaumont2012 argue that using $\tilde{\Sigma}_{ab}$ instead of $\Sigma_{ab}$ should only result in a small overestimation.

## Usage with the Generalized Bootstrap

When the function `as_gen_boot_design()` is used to create generalized bootstrap replicate weights, it will warn you if the target variance estimator is not positive semidefinite and will let you know that it will therefore approximate the target variance estimator using the method described above.

```{r}
gen_boot_design <- as_gen_boot_design(
  design = twophase_design,
  variance_estimator = list(
    'Phase 1' = "Ultimate Cluster",
    'Phase 2' = "Ultimate Cluster"
  )
)
```

## Helper Functions for Ensuring an Estimator is Positive Semidefinite

The 'svrep' package has two functions which can be helpful for dealing with matrices which we hope are positive semidefinite but which might not be.

The function `is_psd_matrix()` simply checks whether a matrix is positive semidefinite. It works by estimating the matrix's eigenvalues and determining whether any of them are negative.

```{r}
twophase_quad_form_matrix <- get_design_quad_form(
  design = twophase_design,
  variance_estimator = list(
    'Phase 1' = "Ultimate Cluster",
    'Phase 2' = "Ultimate Cluster"
  )
)

twophase_quad_form_matrix |> is_psd_matrix()
```

If the matrix isn't positive semidefinite (but is at least symmetric), then the function `get_nearest_psd_matrix()` will implement the approximation method described earlier.

Approximating this quadratic form by one which *is* positive semidefinite leads to a very similar (but slightly larger) estimated standard error.

```{r}
approx_quad_form <- get_nearest_psd_matrix(twophase_quad_form_matrix)
```

In the example two-phase design based on the library survey from earlier, we can see that this approximation results in a standard error estimate which is only slightly larger than the standard error estimate based on the quadratic form which wasn't quite positive semidefinite.

```{r}
std_error <- as.numeric(
  t(wtd_y) %*% twophase_quad_form_matrix %*% wtd_y
) |> sqrt()

approx_std_error <- as.numeric(
  t(wtd_y) %*% approx_quad_form %*% wtd_y
) |> sqrt()

print(approx_std_error)
print(std_error)
```

# References




