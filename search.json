[{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://bschneidr.github.io/svrep/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://bschneidr.github.io/svrep/articles/nonresponse-adjustments.html","id":"creating-initial-replicate-weights","dir":"Articles","previous_headings":"","what":"Creating initial replicate weights","title":"Nonresponse Adjustments","text":"begin , ’ll create bootstrap replicate weights using .svrepdesign() function survey package. initial step describe survey design using svydesign() function create appropriate replicate weights using .svrepdesign() additional arguments type (options 'JK1', 'JKn', 'bootstrap', 'BRR', 'Fay', etc.) beginning, replicate weights allow us estimate variance unadjusted estimates caused random sampling. Note creating initial replicate weights, almost always necessary use data entire selected sample (.e. respondents well nonrespondents). convenience, ’ll convert survey design object object class tbl_svy, allows us use convenient tidyverse/dplyr syntax (group_by(), summarize(), etc.) well helpful functions srvyr package.","code":"# Describe the survey design lou_vax_survey <- svydesign(ids = ~ 1, weights = ~ SAMPLING_WEIGHT,                             data = lou_vax_survey)  print(lou_vax_survey) #> Independent Sampling design (with replacement) #> svydesign(ids = ~1, weights = ~SAMPLING_WEIGHT, data = lou_vax_survey)  # Create appropriate replicate weights lou_vax_survey <- lou_vax_survey |>   as.svrepdesign(type = \"boot\", replicates = 100, mse = TRUE)  print(lou_vax_survey) #> Call: as.svrepdesign.default(lou_vax_survey, type = \"boot\", replicates = 100,  #>     mse = TRUE) #> Survey bootstrap with 100 replicates and MSE variances. lou_vax_survey <- lou_vax_survey |> as_survey()  print(lou_vax_survey) #> Call: Called via srvyr #> Survey bootstrap with 100 replicates and MSE variances. #> Data variables: RESPONSE_STATUS (chr), RACE_ETHNICITY (chr), SEX (chr), #>   EDUC_ATTAINMENT (chr), VAX_STATUS (chr), SAMPLING_WEIGHT (dbl)"},{"path":"https://bschneidr.github.io/svrep/articles/nonresponse-adjustments.html","id":"redistributing-weight-from-nonrespondents-to-respondents","dir":"Articles","previous_headings":"","what":"Redistributing weight from nonrespondents to respondents","title":"Nonresponse Adjustments","text":"common form nonresponse adjustment simply ‘redistribute’ weight nonrespondents respondents. words, weight nonrespondent set \\(0\\), weight respondent increased factor greater one sum adjusted weights sample respondents equals sum unadjusted weights full sample. example, sum weights among respondents \\(299,544.4\\) sum weights among nonrespondents \\(297,157.6\\), basic nonresponse adjustment set weights among nonrespondents \\(0\\) multiply weight respondent adjustment factor equal \\(1 + (297,157.6/299,544.4)\\). type adjustment succinctly described mathematical notation . ’ll illustrate type adjustment Louisville vaccination survey. First, ’ll inspect sum sampling weights respondents, nonrespondents, overall sample. Next, ’ll redistribute weight nonrespondents respondents using redistribute_weights() function, adjusts full-sample weights well set replicate weights. specify subset data weights reduced, supply logical expression argument reduce_if. specify subset data weights increased, supply logical expression argument increase_if. making adjustment, can check weight nonrespondents redistributed respondents.","code":"# Weights before adjustment lou_vax_survey |>   group_by(RESPONSE_STATUS) |>   cascade(     `Sum of Weights` = sum(cur_svy_wts()),     .fill = \"TOTAL\"   ) #> # A tibble: 3 × 2 #>   RESPONSE_STATUS `Sum of Weights` #>   <chr>                      <dbl> #> 1 Nonrespondent            297158. #> 2 Respondent               299544. #> 3 TOTAL                    596702 # Conduct a basic nonresponse adjustment nr_adjusted_survey <- lou_vax_survey |>   redistribute_weights(     reduce_if = RESPONSE_STATUS == \"Nonrespondent\",     increase_if = RESPONSE_STATUS == \"Respondent\"   ) # Check the sum of full-sample weights by response status nr_adjusted_survey |>   group_by(RESPONSE_STATUS) |>   cascade(     `Sum of Weights` = sum(cur_svy_wts()),     .fill = \"TOTAL\"   ) #> # A tibble: 3 × 2 #>   RESPONSE_STATUS `Sum of Weights` #>   <chr>                      <dbl> #> 1 Nonrespondent                  0 #> 2 Respondent                596702 #> 3 TOTAL                     596702 # Check sums of replicate weights by response status nr_adjusted_survey |>   summarize_rep_weights(     type = \"specific\",     by = \"RESPONSE_STATUS\"   ) |>    arrange(Rep_Column, RESPONSE_STATUS) |>   head(10) #>    RESPONSE_STATUS Rep_Column   N N_NONZERO    SUM     MEAN        CV MIN #> 1    Nonrespondent          1 498         0      0    0.000       NaN   0 #> 2       Respondent          1 502       340 596702 1188.649 0.9202522   0 #> 3    Nonrespondent          2 498         0      0    0.000       NaN   0 #> 4       Respondent          2 502       308 596702 1188.649 1.0241458   0 #> 5    Nonrespondent          3 498         0      0    0.000       NaN   0 #> 6       Respondent          3 502       322 596702 1188.649 0.9808791   0 #> 7    Nonrespondent          4 498         0      0    0.000       NaN   0 #> 8       Respondent          4 502       324 596702 1188.649 0.9640530   0 #> 9    Nonrespondent          5 498         0      0    0.000       NaN   0 #> 10      Respondent          5 502       336 596702 1188.649 0.9082631   0 #>         MAX #> 1     0.000 #> 2  5566.250 #> 3     0.000 #> 4  6126.304 #> 5     0.000 #> 6  5618.663 #> 7     0.000 #> 8  5884.635 #> 9     0.000 #> 10 4689.210"},{"path":"https://bschneidr.github.io/svrep/articles/nonresponse-adjustments.html","id":"conducting-weighting-class-adjustments","dir":"Articles","previous_headings":"","what":"Conducting weighting class adjustments","title":"Nonresponse Adjustments","text":"Nonresponse bias liable occur different subpopulations systematically differ terms response rates survey also differ terms survey trying measure (case, vaccination status). example, can see fairly large differences response rates across different race/ethnicity groups. Weighting adjustments may able help reduce nonresponse bias caused differences response rates. One standard form adjustment known weighting class adjustment redistribute weights nonrespondents respondents separately different categories auxiliary variables (race/ethnicity). survey textbook Heeringa, West, Berglund (2017) provides excellent overview weighting class adjustments. implement weighting class adjustment svrep package, can simply use argument redistribute_weights(). Multiple grouping variables may supplied argument. example, one can specify = c(\"STRATUM\", \"RACE_ETHNICITY\") redistribute weights separately combinations stratum race/ethnicity category.","code":"lou_vax_survey |>   group_by(RACE_ETHNICITY) |>   summarize(Response_Rate = mean(RESPONSE_STATUS == \"Respondent\"),             Sample_Size = n(),             n_Respondents = sum(RESPONSE_STATUS == \"Respondent\")) #> # A tibble: 4 × 4 #>   RACE_ETHNICITY                                         Respo…¹ Sampl…² n_Res…³ #>   <chr>                                                    <dbl>   <int>   <int> #> 1 Black or African American alone, not Hispanic or Lati…   0.452     188      85 #> 2 Hispanic or Latino                                       0.378      45      17 #> 3 Other Race, not Hispanic or Latino                       0.492      59      29 #> 4 White alone, not Hispanic or Latino                      0.524     708     371 #> # … with abbreviated variable names ¹​Response_Rate, ²​Sample_Size, #> #   ³​n_Respondents nr_adjusted_survey <- lou_vax_survey |>   redistribute_weights(     reduce_if = RESPONSE_STATUS == \"Nonrespondent\",     increase_if = RESPONSE_STATUS == \"Respondent\",     by = c(\"RACE_ETHNICITY\")   )"},{"path":"https://bschneidr.github.io/svrep/articles/nonresponse-adjustments.html","id":"propensity-cell-adjustment","dir":"Articles","previous_headings":"Conducting weighting class adjustments","what":"Propensity cell adjustment","title":"Nonresponse Adjustments","text":"popular method forming weighting classes based estimated response propensities (known propensity cell adjustment) can also used, example adding variable PROPENSITY_CELL data using redistribute_weights(..., = \"PROPENSITY_CELL\").","code":"# Fit a response propensity model response_propensity_model <- lou_vax_survey |>   mutate(IS_RESPONDENT = ifelse(RESPONSE_STATUS == \"Respondent\", 1, 0)) |>   svyglm(formula = IS_RESPONDENT ~ RACE_ETHNICITY + EDUC_ATTAINMENT,          family = quasibinomial(link = 'logit'))  # Predict response propensities for individual cases lou_vax_survey <- lou_vax_survey |>   mutate(     RESPONSE_PROPENSITY = predict(response_propensity_model,                                   newdata = cur_svy(),                                   type = \"response\")   )  # Divide sample into propensity classes lou_vax_survey <- lou_vax_survey |>   mutate(PROPENSITY_CELL = ntile(x = RESPONSE_PROPENSITY, n = 5))  lou_vax_survey |>     group_by(PROPENSITY_CELL) |>     summarize(n = n(),               min = min(RESPONSE_PROPENSITY),               mean = mean(RESPONSE_PROPENSITY),               max = max(RESPONSE_PROPENSITY)) #> # A tibble: 5 × 5 #>   PROPENSITY_CELL     n   min  mean   max #>             <int> <int> <dbl> <dbl> <dbl> #> 1               1   200 0.357 0.424 0.459 #> 2               2   200 0.459 0.484 0.488 #> 3               3   200 0.488 0.488 0.512 #> 4               4   200 0.512 0.551 0.564 #> 5               5   200 0.564 0.564 0.564  # Redistribute weights by propensity class nr_adjusted_survey <- lou_vax_survey |>   redistribute_weights(     reduce_if = RESPONSE_STATUS == \"Nonrespondent\",     increase_if = RESPONSE_STATUS == \"Respondent\",     by = \"PROPENSITY_CELL\"   )  # Inspect weights before adjustment  lou_vax_survey |>   summarize_rep_weights(type = \"specific\",                         by = c(\"PROPENSITY_CELL\")) |>   arrange(Rep_Column, PROPENSITY_CELL) |>   select(PROPENSITY_CELL, Rep_Column,          N_NONZERO, SUM) |>   head(10) #>    PROPENSITY_CELL Rep_Column N_NONZERO      SUM #> 1                1          1       136 122323.9 #> 2                2          1       122 108599.8 #> 3                3          1       125 122323.9 #> 4                4          1       127 115760.2 #> 5                5          1       130 127694.2 #> 6                1          2       118 108599.8 #> 7                2          2       120 111583.3 #> 8                3          2       132 130081.0 #> 9                4          2       132 121727.2 #> 10               5          2       121 124710.7  # Inspect weights after adjustment nr_adjusted_survey |>   summarize_rep_weights(type = \"specific\",                         by = c(\"PROPENSITY_CELL\", \"RESPONSE_STATUS\")) |>   arrange(Rep_Column, PROPENSITY_CELL, RESPONSE_STATUS) |>   select(PROPENSITY_CELL, RESPONSE_STATUS, Rep_Column,          N_NONZERO, SUM) |>   head(10) #>    PROPENSITY_CELL RESPONSE_STATUS Rep_Column N_NONZERO      SUM #> 1                1   Nonrespondent          1         0      0.0 #> 2                1      Respondent          1        64 122323.9 #> 3                2   Nonrespondent          1         0      0.0 #> 4                2      Respondent          1        58 108599.8 #> 5                3   Nonrespondent          1         0      0.0 #> 6                3      Respondent          1        65 122323.9 #> 7                4   Nonrespondent          1         0      0.0 #> 8                4      Respondent          1        73 115760.2 #> 9                5   Nonrespondent          1         0      0.0 #> 10               5      Respondent          1        80 127694.2"},{"path":"https://bschneidr.github.io/svrep/articles/nonresponse-adjustments.html","id":"saving-the-final-weights-to-a-data-file","dir":"Articles","previous_headings":"","what":"Saving the final weights to a data file","title":"Nonresponse Adjustments","text":"’re satisfied weights, can create data frame analysis variables columns replicate weights. format easy export data files can loaded R software later.","code":"data_frame_with_nr_adjusted_weights <- nr_adjusted_survey |>   as_data_frame_with_weights(     full_wgt_name = \"NR_ADJ_WGT\",     rep_wgt_prefix = \"NR_ADJ_REP_WGT_\"   )  # Preview first few column names colnames(data_frame_with_nr_adjusted_weights) |> head(12) #>  [1] \"RESPONSE_STATUS\"     \"RACE_ETHNICITY\"      \"SEX\"                 #>  [4] \"EDUC_ATTAINMENT\"     \"VAX_STATUS\"          \"SAMPLING_WEIGHT\"     #>  [7] \"RESPONSE_PROPENSITY\" \"PROPENSITY_CELL\"     \"NR_ADJ_WGT\"          #> [10] \"NR_ADJ_REP_WGT_1\"    \"NR_ADJ_REP_WGT_2\"    \"NR_ADJ_REP_WGT_3\" # Write the data to a CSV file write.csv(   x = data_frame_with_nr_adjusted_weights,   file = \"survey-data-with-nonresponse-adjusted-weights.csv\" )"},{"path":"https://bschneidr.github.io/svrep/articles/nonresponse-adjustments.html","id":"statistical-background","dir":"Articles","previous_headings":"","what":"Statistical background","title":"Nonresponse Adjustments","text":"motivation making adjustment standard methods statistical inference assume every person population known, nonzero probability participating survey (.e. nonzero chance sampled nonzero chance responding sampled), denoted \\(p_{,overall}\\). Basic results survey sampling theory guarantee assumption true, can produce unbiased estimates population means totals weighting data respondent weight \\(1/{p_{,overall}}\\). Crucially, overall probability participation \\(p_{,overall}\\) product two components: probability person sampled (denoted \\(\\pi_i\\)), probability person respond survey sampled (denoted \\(p_i\\) referred “response propensity”). sampling probability \\(\\pi_i\\) known since can control method sampling, response propensity \\(p_i\\) unknown can estimated. \\[ \\begin{aligned} w^{*}_i &= 1/p_{,overall} \\text{ (weights needed unbiased estimation)} \\\\ p_{,overall} &= \\pi_i \\times p_i \\\\ \\pi_i &= \\textbf{Sampling probability} \\\\ &\\textit{.e. probability case }\\textit{ randomly sampled } \\text{ (}\\textit{Known}\\text{)} \\\\ p_i &= \\textbf{Response propensity} \\\\ &\\textit{.e. probability case }\\textit{ responds, sampled } \\text{ (}\\textit{Unknown}\\text{)}  \\\\ \\end{aligned} \\] component \\(p_i\\) must estimated using data (estimate \\(\\hat{p}_i\\)) nonresponse-adjusted weights respondents can formed \\(w_{NR,} = 1/(\\pi_i \\times \\hat{p}_i)\\) used obtain approximately unbiased estimates population means totals. use earlier notation, nonresponse adjustment factor respondents \\(f_{NR,}\\) actually defined using \\(1/\\hat{p}_i\\). \\[ \\begin{aligned} w_i &= \\textit{Original sampling weight case }\\\\     &= 1/\\pi_i, \\textit{ } \\pi_i \\textit{ probability case }\\textit{sampled}\\\\ w_{NR, } &= w_i \\times f_{NR,} = \\textit{Weight case }\\textit{ nonresponse adjustment} \\\\ \\\\ f_{NR,} &= \\begin{cases}   0 & \\text{case } \\text{ nonrespondent} \\\\   1 / \\hat{p}_i & \\text{case } \\text{ respondent} \\\\ \\end{cases} \\\\ \\hat{p}_i &= \\textbf{Estimated response propensity} \\end{aligned} \\] essence, different methods nonresponse weighting adjustments vary terms estimate \\(\\hat{p}_i\\). basic weight redistribution method effect estimates \\(p_i\\) constant across \\(\\), equal overall weighted response rate, uses form weights. words, basic weight redistribution essentially way forming adjustment factor \\(f_{NR,}\\) based estimated response propensity \\(\\hat{p}_i = \\frac{\\sum_{\\s_{resp}}w_i}{\\sum_{\\s}w_i}\\). Weighting class adjustments propensity cell adjustments essentially refined ways forming \\(f_{NR,}\\) estimating \\(p_i\\) realistic model, \\(p_i\\) constant across entire sample instead varies among weighting classes propensity cells. reason conducting weighting adjustments full-sample weights replicate weights account nonresponse adjustment process estimating sampling variances inferential statistics confidence intervals. random sampling, adjustment factors used nonresponse adjustment vary one sample next, applying weighting adjustments separately replicate reflects variability. ’ve seen vignette, redistribute_weights() function handles us: nonresponse adjustment, weight replicate redistributed manner weight redistributed full-sample weights.","code":""},{"path":"https://bschneidr.github.io/svrep/articles/nonresponse-adjustments.html","id":"recommended-reading","dir":"Articles","previous_headings":"","what":"Recommended Reading","title":"Nonresponse Adjustments","text":"See Chapter 2, Section 2.7.3 “Applied Survey Data Analysis” statistical explanation weighting adjustments described vignette. Heeringa, S., West, B., Berglund, P. (2017). Applied Survey Data Analysis, 2nd edition. Boca Raton, FL: CRC Press. Chapter 13 “Practical Tools Designing Weighting Survey Samples” also provides excellent overview nonresponse adjustment methods. Valliant, R., Dever, J., Kreuter, F. (2018). Practical Tools Designing Weighting Survey Samples, 2nd edition. New York: Springer.","code":""},{"path":"https://bschneidr.github.io/svrep/articles/sample-based-calibration.html","id":"sample-based-calibration-an-introduction","dir":"Articles","previous_headings":"","what":"Sample-based Calibration: An Introduction","title":"Calibrating to Estimated Control Totals","text":"Calibration weighting adjustments post-stratification raking often helpful reducing sampling variance non-sampling errors nonresponse bias. Typically, benchmark data used calibration adjustments estimates published agencies United States Census Bureau. example, pollsters United States frequently rake polling data estimates variables age educational attainment match benchmark estimates American Community Survey (ACS). benchmark data (also known control totals) raking calibration often treated “true” population values, usually estimates sampling variance margin error. calibrate estimated control totals rather “true” population values, may need account variance estimated control totals ensure calibrated estimates appropriately reflect sampling error primary survey interest survey control totals estimated. especially important control totals large margins error. handful statistical methods developed problem conducting replication variance estimation sample-based calibration; see Opsomer Erciulescu (2021) clear overview literature topic. methods apply calibration weighting adjustment full-sample weights column replicate weights. key “trick” methods adjust column replicate weights slightly different set control totals, varying control totals used across replicates way variation across columns sense proportionate sampling variance control totals. statistical methods differ way generate different control totals column replicate weights type data require analyst use. method Fuller (1998) requires analyst variance-covariance matrix estimated control totals, method Opsomer Erciulescu (2021) requires analyst use full dataset control survey along associated replicate weights.","code":""},{"path":"https://bschneidr.github.io/svrep/articles/sample-based-calibration.html","id":"functions-for-implementing-sample-based-calibration","dir":"Articles","previous_headings":"","what":"Functions for Implementing Sample-Based Calibration","title":"Calibrating to Estimated Control Totals","text":"‘svrep’ package provides two functions implement sample-based calibration. function calibrate_to_estimate(), adjustments replicate weights conducted using method Fuller (1998), requiring variance-covariance matrix estimated control totals. function calibrate_to_sample(), adjustments replicate weights conducted using method proposed Opsomer Erciulescu (2021), requiring dataset replicate weights use estimating control totals sampling variance. functions, possible use variety calibration options survey package’s calibrate() function. example, user can specify specific calibration function use, calfun = survey::cal.linear implement post-stratification calfun = survey::cal.raking implement raking. bounds argument can used specify bounds calibration weights, arguments maxit epsilon allow finer control Newton-Raphson algorithm used implement calibration.","code":"calibrate_to_estimate(   rep_design = rep_design,   estimate = vector_of_control_totals,   vcov_estimate = variance_covariance_matrix_for_controls,   cal_formula = ~ CALIBRATION_VARIABLE_1 + CALIBRATION_VARIABLE_2 + ..., ) calibrate_to_sample(   primary_rep_design = primary_rep_design,   control_rep_design = control_rep_design   cal_formula = ~ CALIBRATION_VARIABLE_1 + CALIBRATION_VARIABLE_2 + ..., )"},{"path":"https://bschneidr.github.io/svrep/articles/sample-based-calibration.html","id":"an-example-using-a-vaccination-survey","dir":"Articles","previous_headings":"","what":"An Example Using a Vaccination Survey","title":"Calibrating to Estimated Control Totals","text":"illustrate different methods conducting sample-based calibration, ’ll use example survey measuring Covid-19 vaccination status handful demographic variables, based simple random sample 1,000 residents Louisville, Kentucky. purpose variance estimation, ’ll create jackknife replicate weights. survey’s key outcome, vaccination status, measured respondents, ’ll quick nonresponse weighting adjustment help make reasonable estimates outcome. work far given us replicate design primary survey, prepared calibration. Now need obtain benchmark data can use calibration. ’ll use Public-Use Microdata Sample (PUMS) dataset ACS source benchmark data race/ethnicity, sex, educational attainment. Next, ’ll prepare PUMS data use replication variance estimation using provided replicate weights. conduction calibration, make sure data control survey represent population primary survey. Since Louisville vaccination survey represents adults, need subset control survey design adults. addition, need ensure control survey design calibration variables align variables primary survey design interest. may require data manipulation.","code":"# Load the data library(svrep) data(\"lou_vax_survey\")  # Inspect the first few rows head(lou_vax_survey) |> knitr::kable() suppressPackageStartupMessages(   library(survey) )  lou_vax_survey_rep <- svydesign(   data = lou_vax_survey,   ids = ~ 1, weights = ~ SAMPLING_WEIGHT ) |>    as.svrepdesign(type = \"JK1\", mse = TRUE) #> Call: as.svrepdesign.default(svydesign(data = lou_vax_survey, ids = ~1,  #>     weights = ~SAMPLING_WEIGHT), type = \"JK1\", mse = TRUE) #> Unstratified cluster jacknife (JK1) with 1000 replicates and MSE variances. # Conduct nonresponse weighting adjustment  nr_adjusted_design <- lou_vax_survey_rep |>   redistribute_weights(     reduce_if = RESPONSE_STATUS == \"Nonrespondent\",     increase_if = RESPONSE_STATUS == \"Respondent\"   ) |>   subset(RESPONSE_STATUS == \"Respondent\")  # Inspect the result of the adjustment rbind(   'Original' = summarize_rep_weights(lou_vax_survey_rep, type = 'overall'),   'NR-adjusted' = summarize_rep_weights(nr_adjusted_design, type = 'overall') )[,c(\"nrows\", \"rank\", \"avg_wgt_sum\", \"sd_wgt_sums\")] #>             nrows rank avg_wgt_sum  sd_wgt_sums #> Original     1000 1000      596702 0.000000e+00 #> NR-adjusted   502  502      596702 8.219437e-11 data(\"lou_pums_microdata\") # Inspect some of the rows/columns of data ---- tail(lou_pums_microdata, n = 5) |>    dplyr::select(AGE, SEX, RACE_ETHNICITY, EDUC_ATTAINMENT) |>   knitr::kable() # Convert to a survey design object ----   pums_rep_design <- svrepdesign(       data = lou_pums_microdata,       weights = ~ PWGTP,       repweights = \"PWGTP\\\\d{1,2}\",       type = \"successive-difference\",       variables = ~ AGE + SEX + RACE_ETHNICITY + EDUC_ATTAINMENT,       mse = TRUE     )    pums_rep_design #> Call: svrepdesign.default(data = lou_pums_microdata, weights = ~PWGTP,  #>     repweights = \"PWGTP\\\\d{1,2}\", type = \"successive-difference\",  #>     variables = ~AGE + SEX + RACE_ETHNICITY + EDUC_ATTAINMENT,  #>     mse = TRUE) #> with 80 replicates and MSE variances. # Subset to only include adults pums_rep_design <- pums_rep_design |> subset(AGE >= 18) suppressPackageStartupMessages(   library(dplyr) )  # Check that variables match across data sources ----   pums_rep_design$variables |>     dplyr::distinct(RACE_ETHNICITY) #>                                            RACE_ETHNICITY #> 1 Black or African American alone, not Hispanic or Latino #> 2                     White alone, not Hispanic or Latino #> 3                                      Hispanic or Latino #> 4                      Other Race, not Hispanic or Latino    setdiff(lou_vax_survey_rep$variables$RACE_ETHNICITY,           pums_rep_design$variables$RACE_ETHNICITY) #> character(0)   setdiff(lou_vax_survey_rep$variables$SEX,           pums_rep_design$variables$SEX) #> character(0)   setdiff(lou_vax_survey_rep$variables$EDUC_ATTAINMENT,           pums_rep_design$variables$EDUC_ATTAINMENT) #> character(0) # Estimates from the control survey (ACS) svymean(   design = pums_rep_design,   x = ~ RACE_ETHNICITY + SEX + EDUC_ATTAINMENT ) #>                                                                          mean #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino 0.19950 #> RACE_ETHNICITYHispanic or Latino                                      0.04525 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                      0.04631 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                     0.70894 #> SEXMale                                                               0.47543 #> SEXFemale                                                             0.52457 #> EDUC_ATTAINMENTHigh school or beyond                                  0.38736 #> EDUC_ATTAINMENTLess than high school                                  0.61264 #>                                                                           SE #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino 0.0010 #> RACE_ETHNICITYHispanic or Latino                                      0.0002 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                      0.0008 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                     0.0007 #> SEXMale                                                               0.0007 #> SEXFemale                                                             0.0007 #> EDUC_ATTAINMENTHigh school or beyond                                  0.0033 #> EDUC_ATTAINMENTLess than high school                                  0.0033  # Estimates from the primary survey (Louisville vaccination survey) svymean(   design = nr_adjusted_design,   x = ~ RACE_ETHNICITY + SEX + EDUC_ATTAINMENT ) #>                                                                           mean #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino 0.169323 #> RACE_ETHNICITYHispanic or Latino                                      0.033865 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                      0.057769 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                     0.739044 #> SEXFemale                                                             0.535857 #> SEXMale                                                               0.464143 #> EDUC_ATTAINMENTHigh school or beyond                                  0.458167 #> EDUC_ATTAINMENTLess than high school                                  0.541833 #>                                                                           SE #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino 0.0168 #> RACE_ETHNICITYHispanic or Latino                                      0.0081 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                      0.0104 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                     0.0196 #> SEXFemale                                                             0.0223 #> SEXMale                                                               0.0223 #> EDUC_ATTAINMENTHigh school or beyond                                  0.0223 #> EDUC_ATTAINMENTLess than high school                                  0.0223"},{"path":"https://bschneidr.github.io/svrep/articles/sample-based-calibration.html","id":"raking-to-estimated-control-totals","dir":"Articles","previous_headings":"An Example Using a Vaccination Survey","what":"Raking to estimated control totals","title":"Calibrating to Estimated Control Totals","text":"’ll start raking estimates ACS race/ethnicity, sex, educational attainment, first using calibrate_to_sample() method using calibrate_to_estimate() method. calibrate_to_sample() method, need obtain vector point estimates control totals, accompanying variance-covariance matrix estimates. Crucially, note vector control totals names estimates produced using svytotal() primary survey design object whose weights plan adjust. calibrate design estimates, supply estimates variance-covariance matrix calibrate_to_estimate(), supply cal_formula argument formula use svytotal(). use raking adjustment, specify calfun = survey::cal.raking. Now can compare estimated totals calibration variables actual control totals. might intuitively expect, estimated totals survey now match control totals, standard errors estimated totals match standard errors control totals. can now see effect raking adjustment primary estimate interest, overall Covid-19 vaccination rate. raking adjustment reduced estimate vaccination rate one percentage point results similar standard error estimate. Instead raking using vector control totals variance-covariance matrix, instead done raking simply supplying two replicate design objects function calibrate_to_sample(). uses Opsomer-Erciulescu method adjusting replicate weights, contrast calibrate_to_estimate(), uses Fuller’s method adjusting replicate weights. can see two methods yield identical point estimates full-sample weights, standard errors match nearly exactly calibration variables (race/ethnicity, sex, educational attainment). However, small slightly noticeable differences standard errors variables, VAX_STATUS, resulting fact two methods different methods adjusting replicate weights. Opsomer Erciulescu (2021) explain differences two methods discuss Opsomer-Erciulescu method used calibrate_to_sample() may better statistical properties Fuller method used calibrate_to_estimate().","code":"acs_control_totals <- svytotal(   x = ~ RACE_ETHNICITY + SEX + EDUC_ATTAINMENT,   design = pums_rep_design )  control_totals_for_raking <- list(   'estimates' = coef(acs_control_totals),   'variance-covariance' = vcov(acs_control_totals) )  # Inspect point estimates control_totals_for_raking$estimates #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino  #>                                                                119041  #>                                      RACE_ETHNICITYHispanic or Latino  #>                                                                 27001  #>                      RACE_ETHNICITYOther Race, not Hispanic or Latino  #>                                                                 27633  #>                     RACE_ETHNICITYWhite alone, not Hispanic or Latino  #>                                                                423027  #>                                                               SEXMale  #>                                                                283688  #>                                                             SEXFemale  #>                                                                313014  #>                                  EDUC_ATTAINMENTHigh school or beyond  #>                                                                231136  #>                                  EDUC_ATTAINMENTLess than high school  #>                                                                365566  # Inspect a few rows of the control totals' variance-covariance matrix control_totals_for_raking$`variance-covariance`[5:8,5:8] |>   `colnames<-`(NULL) #>                                           [,1]      [,2]        [,3]       [,4] #> SEXMale                              355572.45 -29522.95   129208.95   196840.6 #> SEXFemale                            -29522.95 379494.65    81455.95   268515.8 #> EDUC_ATTAINMENTHigh school or beyond 129208.95  81455.95  4019242.10 -3808577.2 #> EDUC_ATTAINMENTLess than high school 196840.55 268515.75 -3808577.20  4273933.5 svytotal(x = ~ RACE_ETHNICITY + SEX + EDUC_ATTAINMENT,          design = nr_adjusted_design) #>                                                                        total #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino 101035 #> RACE_ETHNICITYHispanic or Latino                                       20207 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                       34471 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                     440989 #> SEXFemale                                                             319747 #> SEXMale                                                               276955 #> EDUC_ATTAINMENTHigh school or beyond                                  273389 #> EDUC_ATTAINMENTLess than high school                                  323313 #>                                                                            SE #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino 10003.0 #> RACE_ETHNICITYHispanic or Latino                                       4824.4 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                       6222.7 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                     11713.1 #> SEXFemale                                                             13301.6 #> SEXMale                                                               13301.6 #> EDUC_ATTAINMENTHigh school or beyond                                  13289.2 #> EDUC_ATTAINMENTLess than high school                                  13289.2 raked_design <- calibrate_to_estimate(   rep_design = nr_adjusted_design,   estimate = control_totals_for_raking$estimates,   vcov_estimate = control_totals_for_raking$`variance-covariance`,   cal_formula = ~ RACE_ETHNICITY + SEX + EDUC_ATTAINMENT,   calfun = survey::cal.raking, # Required for raking   epsilon = 1e-9 ) #> Selection of replicate columns whose control totals will be perturbed will be done at random. #> For tips on reproducible selection, see `help('calibrate_to_estimate')` # Estimated totals after calibration svytotal(x = ~ RACE_ETHNICITY + SEX + EDUC_ATTAINMENT,          design = raked_design) #>                                                                        total #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino 119041 #> RACE_ETHNICITYHispanic or Latino                                       27001 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                       27633 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                     423027 #> SEXFemale                                                             313014 #> SEXMale                                                               283688 #> EDUC_ATTAINMENTHigh school or beyond                                  231136 #> EDUC_ATTAINMENTLess than high school                                  365566 #>                                                                            SE #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino  633.63 #> RACE_ETHNICITYHispanic or Latino                                       107.98 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                       472.41 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                      594.14 #> SEXFemale                                                              616.03 #> SEXMale                                                                596.30 #> EDUC_ATTAINMENTHigh school or beyond                                  2004.80 #> EDUC_ATTAINMENTLess than high school                                  2067.35  # Matches the control totals! cbind(   'total' = control_totals_for_raking$estimates,   'SE' = control_totals_for_raking$`variance-covariance` |>     diag() |> sqrt() ) #>                                                                        total #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino 119041 #> RACE_ETHNICITYHispanic or Latino                                       27001 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                       27633 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                     423027 #> SEXMale                                                               283688 #> SEXFemale                                                             313014 #> EDUC_ATTAINMENTHigh school or beyond                                  231136 #> EDUC_ATTAINMENTLess than high school                                  365566 #>                                                                              SE #> RACE_ETHNICITYBlack or African American alone, not Hispanic or Latino  633.6287 #> RACE_ETHNICITYHispanic or Latino                                       107.9829 #> RACE_ETHNICITYOther Race, not Hispanic or Latino                       472.4107 #> RACE_ETHNICITYWhite alone, not Hispanic or Latino                      594.1448 #> SEXMale                                                                596.2990 #> SEXFemale                                                              616.0314 #> EDUC_ATTAINMENTHigh school or beyond                                  2004.8048 #> EDUC_ATTAINMENTLess than high school                                  2067.3494 estimates_by_design <- svyby_repwts(   rep_designs = list(     \"NR-adjusted\" = nr_adjusted_design,     \"Raked\" = raked_design   ),   FUN = svytotal,   formula = ~ RACE_ETHNICITY + SEX + EDUC_ATTAINMENT )  t(estimates_by_design[,-1]) |>   knitr::kable() raked_design_opsomer_erciulescu <- calibrate_to_sample(   primary_rep_design = nr_adjusted_design,   control_rep_design = pums_rep_design,   cal_formula = ~ RACE_ETHNICITY + SEX + EDUC_ATTAINMENT,   calfun = survey::cal.raking,   epsilon = 1e-9 ) #> Matching between primary and control replicates will be done at random. #> For tips on reproducible matching, see `help('calibrate_to_sample')` estimates_by_design <- svyby_repwts(   rep_designs = list(     \"calibrate_to_estimate()\" = raked_design,     \"calibrate_to_sample()\" = raked_design_opsomer_erciulescu   ),   FUN = svytotal,   formula = ~ VAX_STATUS + RACE_ETHNICITY + SEX + EDUC_ATTAINMENT )  t(estimates_by_design[,-1]) |>   knitr::kable()"},{"path":"https://bschneidr.github.io/svrep/articles/sample-based-calibration.html","id":"post-stratification","dir":"Articles","previous_headings":"An Example Using a Vaccination Survey","what":"Post-stratification","title":"Calibrating to Estimated Control Totals","text":"primary difference post-stratification raking post-stratification essentially involves single calibration variable, population benchmarks provided value variable. Louisville vaccination survey, variable called POSTSTRATUM based combinations race/ethnicity, sex, educational attainment. post-stratify design, can either supply estimates variance-covariance matrix calibrate_to_estimate(), can supply two replicate design objects calibrate_to_sample(). either method, need supply cal_formula argument formula use svytotal(). use post-stratification adjustment (rather raking), specify calfun = survey::cal.linear. raking example, can see full-sample post-stratified estimates exactly two methods. standard errors post-stratification variables essentially identical, standard errors variables differ slightly.","code":"# Create matching post-stratification variable in both datasets   nr_adjusted_design <- nr_adjusted_design |>     transform(POSTSTRATUM = interaction(RACE_ETHNICITY, SEX, EDUC_ATTAINMENT,                                         sep = \"|\"))    pums_rep_design <- pums_rep_design |>     transform(POSTSTRATUM = interaction(RACE_ETHNICITY, SEX, EDUC_ATTAINMENT,                                         sep = \"|\"))      levels(pums_rep_design$variables$POSTSTRATUM) <- levels(     nr_adjusted_design$variables$POSTSTRATUM   )  # Estimate control totals   acs_control_totals <- svytotal(     x = ~ POSTSTRATUM,     design = pums_rep_design   )      poststratification_totals <- list(     'estimate' = coef(acs_control_totals),     'variance-covariance' = vcov(acs_control_totals)   )  # Inspect the control totals   poststratification_totals$estimate |>     as.data.frame() |>     `colnames<-`('estimate') |>     knitr::kable() # Post-stratify the design using the estimates poststrat_design_fuller <- calibrate_to_estimate(   rep_design = nr_adjusted_design,   estimate = poststratification_totals$estimate,   vcov_estimate = poststratification_totals$`variance-covariance`,   cal_formula = ~ POSTSTRATUM, # Specify the post-stratification variable   calfun = survey::cal.linear # This option is required for post-stratification ) #> Selection of replicate columns whose control totals will be perturbed will be done at random. #> For tips on reproducible selection, see `help('calibrate_to_estimate')` # Post-stratify the design using the two samples poststrat_design_opsomer_erciulescu <- calibrate_to_sample(   primary_rep_design = nr_adjusted_design,   control_rep_design = pums_rep_design,   cal_formula = ~ POSTSTRATUM, # Specify the post-stratification variable   calfun = survey::cal.linear # This option is required for post-stratification ) #> Matching between primary and control replicates will be done at random. #> For tips on reproducible matching, see `help('calibrate_to_sample')` estimates_by_design <- svyby_repwts(   rep_designs = list(     \"calibrate_to_estimate()\" = poststrat_design_fuller,     \"calibrate_to_sample()\" = poststrat_design_opsomer_erciulescu   ),   FUN = svymean,   formula = ~ VAX_STATUS + RACE_ETHNICITY + SEX + EDUC_ATTAINMENT )  t(estimates_by_design[,-1]) |>   knitr::kable()"},{"path":"https://bschneidr.github.io/svrep/articles/sample-based-calibration.html","id":"reproducibility","dir":"Articles","previous_headings":"","what":"Reproducibility","title":"Calibrating to Estimated Control Totals","text":"calibration methods calibrate_to_estimate() calibrate_to_sample() involve one element randomization: determining columns replicate weights assigned given perturbation control totals. calibrate_to_sample() method Fuller (1998), control totals vector dimension \\(p\\), \\(p\\) columns replicate weights calibrated \\(p\\) different vectors perturbed control totals, formed using \\(p\\) scaled eigenvectors spectral decomposition control totals’ variance-covariance matrix (sorted order largest smallest eigenvalues). control columns replicate weights calibrated set perturbed control totals, can use function argument col_selection. calibrated survey design object contains element perturbed_control_cols indicates columns calibrated perturbed control totals; can useful save use input col_selection ensure reproducibility. calibrate_to_sample(), matching done columns replicate weights primary survey columns replicate weights control survey. matching done random unless user specifies otherwise using argument control_col_matches. Louisville Vaccination Survey, primary survey 1,000 replicates control survey 80 columns. can match 80 columns 1,000 replicates specifying 1,000 values consisting NA integers 1 80. calibrated survey design object contains element control_column_matches control survey replicate primary survey replicate column matched .","code":"# Randomly select which columns will be assigned to each set of perturbed control totals dimension_of_control_totals <- length(poststratification_totals$estimate)  columns_to_perturb <- sample(x = 1:ncol(nr_adjusted_design$repweights),                              size = dimension_of_control_totals)  print(columns_to_perturb) #>  [1] 228 666 830 521  66 481 103 439 430 710 199 973 921  52 313 809  # Perform the calibration poststratified_design <- calibrate_to_estimate(   rep_design = nr_adjusted_design,   estimate = poststratification_totals$estimate,   vcov_estimate = poststratification_totals$`variance-covariance`,   cal_formula = ~ POSTSTRATUM,   calfun = survey::cal.linear,   col_selection = columns_to_perturb # Specified for reproducibility ) poststratified_design$perturbed_control_cols #> NULL # Randomly match the primary replicates to control replicates set.seed(1999)  column_matching <- rep(NA, times = ncol(nr_adjusted_design$repweights)) column_matching[sample(x = 1:1000, size = 80)] <- 1:80  str(column_matching) #>  int [1:1000] NA NA NA 34 NA NA NA 68 NA NA ...  # Perform the calibration poststratified_design <- calibrate_to_sample(   primary_rep_design = nr_adjusted_design,   control_rep_design = pums_rep_design,   cal_formula = ~ POSTSTRATUM,   calfun = survey::cal.linear,   control_col_matches = column_matching ) str(poststratified_design$control_column_matches) #>  int [1:1000] NA NA NA 34 NA NA NA 68 NA NA ..."},{"path":[]},{"path":"https://bschneidr.github.io/svrep/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ben Schneider. Author, maintainer.","code":""},{"path":"https://bschneidr.github.io/svrep/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Schneider B (2022). svrep: Tools Creating, Updating, Analyzing Survey Replicate Weights. https://github.com/bschneidr/svrep, https://bschneidr.github.io/svrep/.","code":"@Manual{,   title = {svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights},   author = {Ben Schneider},   year = {2022},   note = {https://github.com/bschneidr/svrep, https://bschneidr.github.io/svrep/}, }"},{"path":"https://bschneidr.github.io/svrep/index.html","id":"svrep","dir":"","previous_headings":"","what":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","title":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","text":"svrep provides methods creating, updating, analyzing replicate weights surveys. Functions svrep can used implement adjustments replicate designs (e.g. nonresponse weighting class adjustments) analyze effect replicate weights estimates interest.","code":""},{"path":"https://bschneidr.github.io/svrep/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","text":"can install released version svrep CRAN : can install development version GitHub :","code":"install.packages(\"svrep\") # install.packages(\"devtools\") devtools::install_github(\"bschneidr/svrep\")"},{"path":"https://bschneidr.github.io/svrep/index.html","id":"example-usage","dir":"","previous_headings":"","what":"Example usage","title":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","text":"Suppose replicate-weights survey design object created survey package. survey design object can include respondents, non-respondents, cases unknown eligibility.","code":"library(survey) library(svrep) data(api, package = \"survey\") set.seed(2021)  # Create variable giving response status apiclus1$response_status <- sample(x = c(\"Respondent\", \"Nonrespondent\",                                          \"Ineligible\", \"Unknown eligibility\"),                                    size = nrow(apiclus1),                                    replace = TRUE)  # Create replicate-weights survey design dclus1 <- svydesign(data = apiclus1,                     id = ~dnum, weights = ~pw, fpc = ~fpc)  orig_rep_design <- as.svrepdesign(dclus1)  print(orig_rep_design) #> Call: as.svrepdesign.default(dclus1) #> Unstratified cluster jacknife (JK1) with 15 replicates."},{"path":"https://bschneidr.github.io/svrep/index.html","id":"adjusting-for-non-response-or-unknown-eligibility","dir":"","previous_headings":"Example usage","what":"Adjusting for non-response or unknown eligibility","title":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","text":"common practice adjust weights non-response sampled cases whose eligibility survey unknown. common form adjustment “weight redistribution”: example, weights non-respondents reduced zero, weights respondents correspondingly increased total weight sample unchanged. order account adjustments estimating variances survey statistics, adjustments repeated separately set replicate weights. process can easily implemented using redistribute_weights() function. supplying column names argument redistribute_weights(), adjustments conducted separately different groups. can used conduct nonresponse weighting class adjustments.","code":"# Adjust weights for unknown eligibility ue_adjusted_design <- redistribute_weights(design = orig_rep_design,                                            reduce_if = response_status %in% c(\"Unknown eligibility\"),                                            increase_if = !response_status %in% c(\"Unknown eligibility\")) nr_adjusted_design <- redistribute_weights(design = ue_adjusted_design,                                            reduce_if = response_status == \"Nonrespondent\",                                            increase_if = response_status == \"Respondent\",                                            by = c(\"stype\"))"},{"path":"https://bschneidr.github.io/svrep/index.html","id":"comparing-estimates-from-different-sets-of-weights","dir":"","previous_headings":"Example usage","what":"Comparing estimates from different sets of weights","title":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","text":"order assess whether weighting adjustments impact estimates care , want compare estimates different sets weights. function svyby_repwts() makes easy compare estimates different sets weights. can even test differences estimates two sets weights calculate confidence intervals difference.","code":"# Estimate overall means (and their standard errors) from each design overall_estimates <- svyby_repwts(   rep_designs = list('original' = orig_rep_design,                      'nonresponse-adjusted' = nr_adjusted_design),   formula = ~ api00, FUN = svymean ) print(overall_estimates, row.names = FALSE) #>           Design_Name    api00       se #>  nonresponse-adjusted 646.4465 30.66081 #>              original 644.1694 26.32936  # Estimate domain means (and their standard errors) from each design domain_estimates <- svyby_repwts(   rep_designs = list('original' = orig_rep_design,                      'nonresponse-adjusted' = nr_adjusted_design),   formula = ~ api00, by = ~ stype, FUN = svymean ) print(domain_estimates, row.names = FALSE) #>           Design_Name stype    api00       se #>  nonresponse-adjusted     E 641.9463 34.19443 #>              original     E 648.8681 25.37430 #>  nonresponse-adjusted     H 699.5455 14.24657 #>              original     H 618.5714 46.34412 #>  nonresponse-adjusted     M 643.3429 41.47212 #>              original     M 631.4400 33.68762 estimates <- svyby_repwts(   rep_designs = list('original' = orig_rep_design,                      'nonresponse-adjusted' = nr_adjusted_design),   formula = ~ api00, FUN = svymean )  vcov(estimates) #>                      nonresponse-adjusted original #> nonresponse-adjusted             940.0856 784.1324 #> original                         784.1324 693.2352  diff_between_ests <- svycontrast(stat = estimates,                                  contrasts = list(                                    \"Original vs. Adjusted\" = c(-1,1)                                  )) print(diff_between_ests) #>                       contrast     SE #> Original vs. Adjusted  -2.2771 8.0657 confint(diff_between_ests) #>                           2.5 %   97.5 % #> Original vs. Adjusted -18.08562 13.53147"},{"path":"https://bschneidr.github.io/svrep/index.html","id":"diagnosing-potential-issues-with-weights","dir":"","previous_headings":"Example usage","what":"Diagnosing potential issues with weights","title":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","text":"adjusting replicate weights, several diagnostics can used ensure adjustments carried correctly good harm. function summarize_rep_weights() helps allowing quickly summarize replicate weights. example, carrying nonresponse adjustments, might want verify weights nonrespondents set zero replicate. can use summarize_rep_weights() compare summary statistics replicate, can use argument group summaries one variables. end adjustment process, can inspect number rows columns examine variability weights across replicates.","code":"summarize_rep_weights(   rep_design = nr_adjusted_design,   type = 'specific',   by = \"response_status\" ) |>    subset(Rep_Column %in% 1:2) #>        response_status Rep_Column  N N_NONZERO      SUM     MEAN        CV #> 1           Ineligible          1 50        47 2109.089 42.18178 0.2552106 #> 2           Ineligible          2 50        49 2224.316 44.48631 0.1443075 #> 16       Nonrespondent          1 48         0    0.000  0.00000       NaN #> 17       Nonrespondent          2 48         0    0.000  0.00000       NaN #> 31          Respondent          1 49        49 4128.429 84.25366 0.2403636 #> 32          Respondent          2 49        48 4267.055 87.08275 0.2224368 #> 46 Unknown eligibility          1 36         0    0.000  0.00000       NaN #> 47 Unknown eligibility          2 36         0    0.000  0.00000       NaN #>         MIN       MAX #> 1   0.00000  44.87423 #> 2   0.00000  45.39420 #> 16  0.00000   0.00000 #> 17  0.00000   0.00000 #> 31 70.51665 179.49692 #> 32  0.00000 158.87969 #> 46  0.00000   0.00000 #> 47  0.00000   0.00000 nr_adjusted_design |>   subset(response_status == \"Respondent\") |>   summarize_rep_weights(     type = 'overall'   ) #>   nrows ncols degf_svy_pkg rank avg_wgt_sum sd_wgt_sums min_rep_wgt max_rep_wgt #> 1    49    15           14   15    4087.158    259.0107           0    316.8524"},{"path":"https://bschneidr.github.io/svrep/index.html","id":"sample-based-calibration","dir":"","previous_headings":"Example usage","what":"Sample-based calibration","title":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","text":"rake poststratify estimated control totals rather “true” population values, may need account variance estimated control totals ensure calibrated estimates appropriately reflect sampling error primary survey interest survey control totals estimated. ‘svrep’ package provides two functions accomplish . function calibrate_to_estimate() requires user supply vector control totals variance-covariance matrix, function calibrate_to_sample() requires user supply dataset replicate weights use estimating control totals sampling variance. example, suppose survey measuring vaccination status adults Louisville, Kentucky. variance estimation, use 100 bootstrap replicates. reduce nonresponse bias coverage error survey, can rake survey population totals demographic groups estimated Census Bureau American Community Survey (ACS). estimate population totals raking purposes, can use microdata replicate weights. can see distribution race/ethnicity among respondents differs distribution race/ethnicity ACS benchmarks. two options calibrating sample control totals benchmark survey. first approach, supply point estimates variance-covariance matrix function calibrate_to_estimate(). second approach, supply control survey’s replicate design calibrate_to_sample(). calibration, can see estimated vaccination rate decreased, estimated standard error estimated vaccination rate increased.","code":"data(\"lou_vax_survey\")  # Load example data lou_vax_survey <- svydesign(ids = ~ 1, weights = ~ SAMPLING_WEIGHT,                             data = lou_vax_survey) |>   as.svrepdesign(type = \"boot\", replicates = 100, mse = TRUE)  # Adjust for nonresponse lou_vax_survey <- lou_vax_survey |>   redistribute_weights(     reduce_if = RESPONSE_STATUS == \"Nonrespondent\",     increase_if = RESPONSE_STATUS == \"Respondent\"   ) |>   subset(RESPONSE_STATUS == \"Respondent\") # Load microdata to use for estimating control totals data(\"lou_pums_microdata\")  acs_benchmark_survey <- survey::svrepdesign(   data = lou_pums_microdata,   variables = ~ UNIQUE_ID + AGE + SEX + RACE_ETHNICITY + EDUC_ATTAINMENT,   weights = ~ PWGTP, repweights = \"PWGTP\\\\d{1,2}\",   type = \"successive-difference\",   mse = TRUE ) # Compare demographic estimates from the two data sources estimate_comparisons <- data.frame(   'Vax_Survey' = svymean(x = ~ RACE_ETHNICITY, design = acs_benchmark_survey) |> coef(),   'ACS_Benchmark' = svymean(x = ~ RACE_ETHNICITY, design = lou_vax_survey) |> coef() ) rownames(estimate_comparisons) <- gsub(x = rownames(estimate_comparisons),                                        \"RACE_ETHNICITY\", \"\") print(estimate_comparisons) #>                                                         Vax_Survey #> Black or African American alone, not Hispanic or Latino 0.19949824 #> Hispanic or Latino                                      0.04525039 #> Other Race, not Hispanic or Latino                      0.04630955 #> White alone, not Hispanic or Latino                     0.70894182 #>                                                         ACS_Benchmark #> Black or African American alone, not Hispanic or Latino    0.16932271 #> Hispanic or Latino                                         0.03386454 #> Other Race, not Hispanic or Latino                         0.05776892 #> White alone, not Hispanic or Latino                        0.73904382 # Estimate control totals and their variance-covariance matrix control_totals <- svymean(x = ~ RACE_ETHNICITY + EDUC_ATTAINMENT,                           design = acs_benchmark_survey) point_estimates <- coef(control_totals) vcov_estimates <- vcov(control_totals)  # Calibrate the vaccination survey to the estimated control totals vax_survey_raked_to_estimates <- calibrate_to_estimate(   rep_design = lou_vax_survey,   estimate = point_estimates,   vcov_estimate = vcov_estimates,   cal_formula = ~ RACE_ETHNICITY + EDUC_ATTAINMENT,   calfun = survey::cal.raking ) vax_survey_raked_to_acs_sample <- calibrate_to_sample(   primary_rep_design = lou_vax_survey,   control_rep_design = acs_benchmark_survey,   cal_formula = ~ RACE_ETHNICITY + EDUC_ATTAINMENT,   calfun = survey::cal.raking ) # Compare the two sets of estimates svyby_repwts(   rep_design = list(     'NR-adjusted' = lou_vax_survey,     'Raked to estimate' = vax_survey_raked_to_estimates,     'Raked to sample' = vax_survey_raked_to_acs_sample   ),   formula = ~ VAX_STATUS,   FUN = svymean,   keep.names = FALSE ) #>         Design_Name VAX_STATUSUnvaccinated VAX_STATUSVaccinated        se1 #> 1       NR-adjusted              0.4621514            0.5378486 0.02430176 #> 2 Raked to estimate              0.4732623            0.5267377 0.02448676 #> 3   Raked to sample              0.4732623            0.5267377 0.02446881 #>          se2 #> 1 0.02430176 #> 2 0.02448676 #> 3 0.02446881"},{"path":"https://bschneidr.github.io/svrep/index.html","id":"saving-results-to-a-data-file","dir":"","previous_headings":"Example usage","what":"Saving results to a data file","title":"Tools for Creating, Updating, and Analyzing Survey Replicate Weights","text":"’re satisfied weights, can create data frame analysis variables columns final full-sample weights replicate weights. format easy export data files can loaded R software later.","code":"data_frame_with_final_weights <- vax_survey_raked_to_estimates |>   as_data_frame_with_weights(     full_wgt_name = \"RAKED_WGT\",     rep_wgt_prefix = \"RAKED_REP_WGT_\"   )  # Preview first 10 column names colnames(data_frame_with_final_weights) |> head(10) #>  [1] \"RESPONSE_STATUS\" \"RACE_ETHNICITY\"  \"SEX\"             \"EDUC_ATTAINMENT\" #>  [5] \"VAX_STATUS\"      \"SAMPLING_WEIGHT\" \"RAKED_WGT\"       \"RAKED_REP_WGT_1\" #>  [9] \"RAKED_REP_WGT_2\" \"RAKED_REP_WGT_3\" # Write the data to a CSV file write.csv(   x = data_frame_with_final_weights,   file = \"survey-data_with-updated-weights.csv\" )"},{"path":"https://bschneidr.github.io/svrep/reference/as_data_frame_with_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a survey design object to a data frame with weights stored as columns — as_data_frame_with_weights","title":"Convert a survey design object to a data frame with weights stored as columns — as_data_frame_with_weights","text":"Convert survey design object data frame weights stored columns","code":""},{"path":"https://bschneidr.github.io/svrep/reference/as_data_frame_with_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a survey design object to a data frame with weights stored as columns — as_data_frame_with_weights","text":"","code":"as_data_frame_with_weights(   design,   full_wgt_name = \"FULL_SAMPLE_WGT\",   rep_wgt_prefix = \"REP_WGT_\" )"},{"path":"https://bschneidr.github.io/svrep/reference/as_data_frame_with_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a survey design object to a data frame with weights stored as columns — as_data_frame_with_weights","text":"design survey design object, created either survey srvyr packages. full_wgt_name column name use full-sample weights rep_wgt_prefix replicate design objects, prefix use column names replicate weights. column names created appending replicate number prefix.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/as_data_frame_with_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a survey design object to a data frame with weights stored as columns — as_data_frame_with_weights","text":"data frame, new columns containing weights survey design object","code":""},{"path":"https://bschneidr.github.io/svrep/reference/as_data_frame_with_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a survey design object to a data frame with weights stored as columns — as_data_frame_with_weights","text":"","code":"data(\"lou_vax_survey\", package = 'svrep')  library(survey) #> Loading required package: grid #> Loading required package: Matrix #> Loading required package: survival #>  #> Attaching package: ‘survey’ #> The following object is masked from ‘package:graphics’: #>  #>     dotchart # Create a survey design object survey_design <- svydesign(data = lou_vax_survey,                            weights = ~ SAMPLING_WEIGHT,                            ids = ~ 1)  rep_survey_design <- as.svrepdesign(survey_design,                                     type = \"boot\",                                     replicates = 10)  # Adjust the weights for nonresponse nr_adjusted_design <- redistribute_weights(   design = rep_survey_design,   reduce_if = RESPONSE_STATUS == \"Nonrespondent\",   increase_if = RESPONSE_STATUS == \"Respondent\",   by = c(\"RACE_ETHNICITY\", \"EDUC_ATTAINMENT\") )  # Save the survey design object as a data frame nr_adjusted_data <- as_data_frame_with_weights(   nr_adjusted_design,   full_wgt_name = \"NR_ADJUSTED_WGT\",   rep_wgt_prefix = \"NR_ADJUSTED_REP_WGT_\" ) head(nr_adjusted_data) #>      RESPONSE_STATUS                                          RACE_ETHNICITY #> X1     Nonrespondent                     White alone, not Hispanic or Latino #> X1.1   Nonrespondent Black or African American alone, not Hispanic or Latino #> X3        Respondent                     White alone, not Hispanic or Latino #> X1.2   Nonrespondent                     White alone, not Hispanic or Latino #> X1.3   Nonrespondent                     White alone, not Hispanic or Latino #> X6        Respondent                     White alone, not Hispanic or Latino #>         SEX       EDUC_ATTAINMENT VAX_STATUS SAMPLING_WEIGHT NR_ADJUSTED_WGT #> X1   Female Less than high school       <NA>         596.702           0.000 #> X1.1 Female High school or beyond       <NA>         596.702           0.000 #> X3   Female Less than high school Vaccinated         596.702        1223.239 #> X1.2 Female Less than high school       <NA>         596.702           0.000 #> X1.3 Female High school or beyond       <NA>         596.702           0.000 #> X6   Female High school or beyond Vaccinated         596.702        1059.068 #>      NR_ADJUSTED_REP_WGT_1 NR_ADJUSTED_REP_WGT_2 NR_ADJUSTED_REP_WGT_3 #> X1                   0.000                 0.000                 0.000 #> X1.1                 0.000                 0.000                 0.000 #> X3                4848.204              1255.489                 0.000 #> X1.2                 0.000                 0.000                 0.000 #> X1.3                 0.000                 0.000                 0.000 #> X6                2173.462                 0.000              1030.387 #>      NR_ADJUSTED_REP_WGT_4 NR_ADJUSTED_REP_WGT_5 NR_ADJUSTED_REP_WGT_6 #> X1                   0.000                 0.000                 0.000 #> X1.1                 0.000                 0.000                 0.000 #> X3                2446.478              2444.865                 0.000 #> X1.2                 0.000                 0.000                 0.000 #> X1.3                 0.000                 0.000                 0.000 #> X6                1005.124              3981.838              2085.381 #>      NR_ADJUSTED_REP_WGT_7 NR_ADJUSTED_REP_WGT_8 NR_ADJUSTED_REP_WGT_9 #> X1                   0.000                 0.000                 0.000 #> X1.1                 0.000                 0.000                 0.000 #> X3                1233.389              1228.693              1250.392 #> X1.2                 0.000                 0.000                 0.000 #> X1.3                 0.000                 0.000                 0.000 #> X6                1082.639                 0.000              1105.753 #>      NR_ADJUSTED_REP_WGT_10 #> X1                        0 #> X1.1                      0 #> X3                        0 #> X1.2                      0 #> X1.3                      0 #> X6                        0  # Check the column names of the result colnames(nr_adjusted_data) #>  [1] \"RESPONSE_STATUS\"        \"RACE_ETHNICITY\"         \"SEX\"                    #>  [4] \"EDUC_ATTAINMENT\"        \"VAX_STATUS\"             \"SAMPLING_WEIGHT\"        #>  [7] \"NR_ADJUSTED_WGT\"        \"NR_ADJUSTED_REP_WGT_1\"  \"NR_ADJUSTED_REP_WGT_2\"  #> [10] \"NR_ADJUSTED_REP_WGT_3\"  \"NR_ADJUSTED_REP_WGT_4\"  \"NR_ADJUSTED_REP_WGT_5\"  #> [13] \"NR_ADJUSTED_REP_WGT_6\"  \"NR_ADJUSTED_REP_WGT_7\"  \"NR_ADJUSTED_REP_WGT_8\"  #> [16] \"NR_ADJUSTED_REP_WGT_9\"  \"NR_ADJUSTED_REP_WGT_10\""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_estimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_estimate","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_estimate","text":"Calibrate weights primary survey match estimated totals control survey, using adjustments replicate weights account variance estimated control totals. adjustments replicate weights conducted using method proposed Fuller (1998). method can used implement general calibration well post-stratification raking specifically (see details calfun parameter).","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_estimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_estimate","text":"","code":"calibrate_to_estimate(   rep_design,   estimate,   vcov_estimate,   cal_formula,   calfun = survey::cal.linear,   bounds = list(lower = -Inf, upper = Inf),   verbose = FALSE,   maxit = 50,   epsilon = 1e-07,   variance = NULL,   col_selection = NULL )"},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_estimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_estimate","text":"rep_design replicate design object primary survey, created either survey srvyr packages. estimate vector estimated control totals. names entries must match names calling svytotal(x = cal_formula, design = rep_design). vcov_estimate variance-covariance matrix estimated control totals. column names row names must match names estimate. cal_formula formula listing variables use calibration. variables must included rep_design. calfun calibration function survey package, cal.linear, cal.raking, cal.logit. Use cal.linear ordinary post-stratification, cal.raking raking. See calibrate additional details. bounds Parameter passed grake calibration. See calibrate details. verbose Parameter passed grake calibration. See calibrate details. maxit Parameter passed grake calibration. See calibrate details. epsilon Parameter passed grake calibration.  calibration, absolute difference calibration target calibrated estimate larger epsilon times (1 plus absolute value target). See calibrate details. variance Parameter passed grake calibration. See calibrate details. col_selection Optional parameter determine replicate columns control totals perturbed. supplied, col_selection must integer vector length equal length estimate.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_estimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_estimate","text":"replicate design object, full-sample weights calibrated totals estimate, replicate weights adjusted account variance control totals. element col_selection indicates, replicate column calibrated primary survey, column replicate weights matched control survey.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_estimate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_estimate","text":"Fuller method, k randomly-selected replicate columns primary survey calibrated control totals formed perturbing k-dimensional vector estimated control totals using spectral decomposition variance-covariance matrix estimated control totals. replicate columns simply calibrated unperturbed control totals. set replicate columns whose control totals perturbed random, multiple ways ensure matching reproducible. user can either call set.seed using function, supply vector randomly-selected column indices argument col_selection.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_estimate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_estimate","text":"Fuller, W.. (1998). \"Replication variance estimation two-phase samples.\" Statistica Sinica, 8: 1153-1164. Opsomer, J.D. . Erciulescu (2021). \"Replication variance estimation sample-based calibration.\" Survey Methodology, 47: 265-277.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_estimate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_estimate","text":"","code":"# Load example data for primary survey ----    suppressPackageStartupMessages(library(survey))   data(api)    primary_survey <- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc) |>     as.svrepdesign(type = \"JK1\")  # Load example data for control survey ----    control_survey <- svydesign(id = ~ 1, fpc = ~fpc, data = apisrs) |>     as.svrepdesign(type = \"JK1\")  # Estimate control totals ----    estimated_controls <- svytotal(x = ~ stype + enroll,                                  design = control_survey)   control_point_estimates <- coef(estimated_controls)   control_vcov_estimate <- vcov(estimated_controls)  # Calibrate totals for one categorical variable and one numeric ----    calibrated_rep_design <- calibrate_to_estimate(     rep_design = primary_survey,     estimate = control_point_estimates,     vcov_estimate = control_vcov_estimate,     cal_formula = ~ stype + enroll   ) #> Selection of replicate columns whose control totals will be perturbed will be done at random. #> For tips on reproducible selection, see `help('calibrate_to_estimate')` #> Warning: Setting `mse` to TRUE; variance estimates will be centered around full-sample estimate, not mean of replicates.  # Inspect estimates before and after calibration ----    ##_ For the calibration variables, estimates and standard errors   ##_ from calibrated design will match those of the control survey      svytotal(x = ~ stype + enroll, design = primary_survey) #>             total        SE #> stypeE    4873.97   1333.32 #> stypeH     473.86    158.70 #> stypeM     846.17    167.55 #> enroll 3404940.13 932235.03     svytotal(x = ~ stype + enroll, design = control_survey) #>             total        SE #> stypeE    4397.74    196.00 #> stypeH     774.25    142.85 #> stypeM    1022.01    160.33 #> enroll 3621074.34 169519.65     svytotal(x = ~ stype + enroll, design = calibrated_rep_design) #>             total        SE #> stypeE    4397.74    196.00 #> stypeH     774.25    142.85 #> stypeM    1022.01    160.33 #> enroll 3621074.34 169519.65    ##_ Estimates from other variables will be changed as well      svymean(x = ~ api00 + api99, design = primary_survey) #>         mean     SE #> api00 644.17 26.329 #> api99 606.98 26.998     svymean(x = ~ api00 + api99, design = control_survey) #>         mean     SE #> api00 656.58 9.2497 #> api99 624.68 9.5003     svymean(x = ~ api00 + api99, design = calibrated_rep_design) #>         mean     SE #> api00 642.69 27.344 #> api99 606.91 28.270  # Inspect weights before and after calibration ----    summarize_rep_weights(primary_survey, type = 'overall') #>   nrows ncols degf_svy_pkg rank avg_wgt_sum sd_wgt_sums min_rep_wgt max_rep_wgt #> 1   183    15           14   15        6194    403.1741           0    36.26464   summarize_rep_weights(calibrated_rep_design, type = 'overall') #>   nrows ncols degf_svy_pkg rank avg_wgt_sum  sd_wgt_sums min_rep_wgt #> 1   183    15           14   15        6194 4.905592e-09           0 #>   max_rep_wgt #> 1    119.1069  # For reproducibility, specify which columns are randomly selected for Fuller method ----    column_selection <- calibrated_rep_design$col_selection   print(column_selection) #> [1]  4  1 11 12    calibrated_rep_design <- calibrate_to_estimate(     rep_design = primary_survey,     estimate = control_point_estimates,     vcov_estimate = control_vcov_estimate,     cal_formula = ~ stype + enroll,     col_selection = column_selection   ) #> Warning: Setting `mse` to TRUE; variance estimates will be centered around full-sample estimate, not mean of replicates."},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_sample","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_sample","text":"Calibrate weights primary survey match estimated totals control survey, using adjustments replicate weights account variance estimated control totals. adjustments replicate weights conducted using method proposed Opsomer Erciulescu (2021). method can used implement general calibration well post-stratification raking specifically (see details calfun parameter).","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_sample","text":"","code":"calibrate_to_sample(   primary_rep_design,   control_rep_design,   cal_formula,   calfun = survey::cal.linear,   bounds = list(lower = -Inf, upper = Inf),   verbose = FALSE,   maxit = 50,   epsilon = 1e-07,   variance = NULL,   control_col_matches = NULL )"},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_sample","text":"primary_rep_design replicate design object primary survey, created either survey srvyr packages. control_rep_design replicate design object control survey. cal_formula formula listing variables use calibration. variables must included primary_rep_design control_rep_design. calfun calibration function survey package, cal.linear, cal.raking, cal.logit. Use cal.linear ordinary post-stratification, cal.raking raking. See calibrate additional details. bounds Parameter passed grake calibration. See calibrate details. verbose Parameter passed grake calibration. See calibrate details. maxit Parameter passed grake calibration. See calibrate details. epsilon Parameter passed grake calibration.  calibration, absolute difference calibration target calibrated estimate larger epsilon times (1 plus absolute value target). See calibrate details. variance Parameter passed grake calibration. See calibrate details. control_col_matches Optional parameter control control survey replicate matched primary survey replicate. Entries NA denote primary survey replicate matched control survey replicate. parameter used, matching done random.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_sample","text":"replicate design object, full-sample weights calibrated totals control_rep_design, replicate weights adjusted account variance control totals. primary_rep_design fewer columns replicate weights control_rep_design, number replicate columns length rscales increased multiple k, scale updated dividing k.   element control_column_matches indicates, replicate column calibrated primary survey, column replicate weights matched control survey. Columns matched control survey replicate column indicated NA.   element degf set match primary survey ensure degrees freedom erroneously inflated potential increases number columns replicate weights.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_sample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_sample","text":"Opsomer-Erciulescu method, column replicate weights control survey randomly matched column replicate weights primary survey, column primary survey calibrated control totals estimated perturbing control sample's full-sample estimates using estimates matched column replicate weights control survey.  fewer columns replicate weights control survey primary survey, primary replicate columns matched replicate column control survey. columns replicate weights control survey primary survey, columns replicate weights primary survey duplicated k times, k smallest positive integer resulting number columns replicate weights primary survey greater equal number columns replicate weights control survey. replicate columns control survey matched random primary survey replicate columns, multiple ways ensure matching reproducible. user can either call set.seed using function, supply mapping argument control_col_matches.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_sample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_sample","text":"Opsomer, J.D. . Erciulescu (2021). \"Replication variance estimation sample-based calibration.\" Survey Methodology, 47: 265-277.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/calibrate_to_sample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrate weights from a primary survey to estimated totals from a control survey,\nwith replicate-weight adjustments that account for variance of the control totals — calibrate_to_sample","text":"","code":"# Load example data for primary survey ----    suppressPackageStartupMessages(library(survey))   data(api)    primary_survey <- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc) |>     as.svrepdesign(type = \"JK1\")  # Load example data for control survey ----    control_survey <- svydesign(id = ~ 1, fpc = ~fpc, data = apisrs) |>     as.svrepdesign(type = \"JK1\")  # Calibrate totals for one categorical variable and one numeric ----    calibrated_rep_design <- calibrate_to_sample(     primary_rep_design = primary_survey,     control_rep_design = control_survey,     cal_formula = ~ stype + enroll,   ) #> The primary survey has fewer replicates than the control survey, so columns in the primary survey will be duplicated 14 times, with suitable adjustments made to `scale` and `rscales`. #> Matching between primary and control replicates will be done at random. #> For tips on reproducible matching, see `help('calibrate_to_sample')` #> Warning: Setting `mse` to TRUE; variance estimates will be centered around full-sample estimate, not mean of replicates.  # Inspect estimates before and after calibration ----    ##_ For the calibration variables, estimates and standard errors   ##_ from calibrated design will match those of the control survey      svytotal(x = ~ stype + enroll, design = primary_survey) #>             total        SE #> stypeE    4873.97   1333.32 #> stypeH     473.86    158.70 #> stypeM     846.17    167.55 #> enroll 3404940.13 932235.03     svytotal(x = ~ stype + enroll, design = control_survey) #>             total        SE #> stypeE    4397.74    196.00 #> stypeH     774.25    142.85 #> stypeM    1022.01    160.33 #> enroll 3621074.34 169519.65     svytotal(x = ~ stype + enroll, design = calibrated_rep_design) #>             total        SE #> stypeE    4397.74    196.00 #> stypeH     774.25    142.85 #> stypeM    1022.01    160.33 #> enroll 3621074.34 169519.65    ##_ Estimates from other variables will be changed as well      svymean(x = ~ api00 + api99, design = primary_survey) #>         mean     SE #> api00 644.17 26.329 #> api99 606.98 26.998     svymean(x = ~ api00 + api99, design = control_survey) #>         mean     SE #> api00 656.58 9.2497 #> api99 624.68 9.5003     svymean(x = ~ api00 + api99, design = calibrated_rep_design) #>         mean     SE #> api00 642.69 27.334 #> api99 606.91 28.279  # Inspect weights before and after calibration ----    summarize_rep_weights(primary_survey, type = 'overall') #>   nrows ncols degf_svy_pkg rank avg_wgt_sum sd_wgt_sums min_rep_wgt max_rep_wgt #> 1   183    15           14   15        6194    403.1741           0    36.26464   summarize_rep_weights(calibrated_rep_design, type = 'overall') #>   nrows ncols degf_svy_pkg rank avg_wgt_sum  sd_wgt_sums min_rep_wgt #> 1   183   210           47   48        6194 1.382331e-09           0 #>   max_rep_wgt #> 1    125.7899  # For reproducibility, specify how to match replicates between surveys ----    column_matching <- calibrated_rep_design$control_col_matches   print(column_matching) #> NULL    calibrated_rep_design <- calibrate_to_sample(     primary_rep_design = primary_survey,     control_rep_design = control_survey,     cal_formula = ~ stype + enroll,     control_col_matches = column_matching   ) #> The primary survey has fewer replicates than the control survey, so columns in the primary survey will be duplicated 14 times, with suitable adjustments made to `scale` and `rscales`. #> Matching between primary and control replicates will be done at random. #> For tips on reproducible matching, see `help('calibrate_to_sample')` #> Warning: Setting `mse` to TRUE; variance estimates will be centered around full-sample estimate, not mean of replicates."},{"path":"https://bschneidr.github.io/svrep/reference/lou_pums_microdata.html","id":null,"dir":"Reference","previous_headings":"","what":"ACS PUMS Data for Louisville — lou_pums_microdata","title":"ACS PUMS Data for Louisville — lou_pums_microdata","text":"Person-level microdata American Community Survey (ACS) 2015-2019 public-use microdata sample (PUMS) data Louisville, KY. microdata sample represents adults (persons aged 18 ) Louisville, KY. data include replicate weights use variance estimation.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/lou_pums_microdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ACS PUMS Data for Louisville — lou_pums_microdata","text":"","code":"data(lou_pums_microdata)"},{"path":"https://bschneidr.github.io/svrep/reference/lou_pums_microdata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ACS PUMS Data for Louisville — lou_pums_microdata","text":"data frame 80 rows 85 variables UNIQUE_ID: Unique identifier records AGE: Age years (copied AGEP variable ACS microdata) RACE_ETHNICITY: Race Hispanic/Latino ethnicity   derived RAC1P HISP variables   ACS microdata collapsed smaller number categories. SEX: Male Female EDUC_ATTAINMENT: Highest level education attained ('Less high school' 'High school beyond')   derived SCHL variable ACS microdata collapsed smaller number categories. PWGTP: Weights full-sample PWGTP1-PWGTP80: 80 columns replicate weights   created using Successive Differences Replication (SDR) method.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/lou_pums_microdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ACS PUMS Data for Louisville — lou_pums_microdata","text":"","code":"data(lou_pums_microdata)  # Prepare the data for analysis with the survey package   library(survey)    lou_pums_rep_design <- survey::svrepdesign(     data = lou_pums_microdata,     variables = ~ UNIQUE_ID + AGE + SEX + RACE_ETHNICITY + EDUC_ATTAINMENT,     weights = ~ PWGTP, repweights = \"PWGTP\\\\d{1,2}\",     type = \"successive-difference\",     mse = TRUE   )  # Estimate population proportions   svymean(~ SEX, design = lou_pums_rep_design) #>              mean    SE #> SEXMale   0.47543 7e-04 #> SEXFemale 0.52457 7e-04"},{"path":"https://bschneidr.github.io/svrep/reference/lou_vax_survey.html","id":null,"dir":"Reference","previous_headings":"","what":"Louisville Vaccination Survey — lou_vax_survey","title":"Louisville Vaccination Survey — lou_vax_survey","text":"survey measuring Covid-19 vaccination status handful demographic variables, based simple random sample 1,000 residents Louisville, Kentucky approximately 50% response rate. data created using simulation.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/lou_vax_survey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Louisville Vaccination Survey — lou_vax_survey","text":"","code":"data(lou_vax_survey)"},{"path":"https://bschneidr.github.io/svrep/reference/lou_vax_survey.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Louisville Vaccination Survey — lou_vax_survey","text":"data frame 1,000 rows 6 variables RESPONSE_STATUS Response status survey ('Respondent' 'Nonrespondent') RACE_ETHNICITY Race Hispanic/Latino ethnicity   derived RAC1P HISP variables   ACS microdata collapsed smaller number categories. SEX Male Female EDUC_ATTAINMENT Highest level education attained ('Less high school' 'High school beyond')   derived SCHL variable ACS microdata collapsed smaller number categories. VAX_STATUS Covid-19 vaccination status ('Vaccinated' 'Unvaccinated') SAMPLING_WEIGHT Sampling weight: equal cases since data come simple random sample","code":""},{"path":"https://bschneidr.github.io/svrep/reference/lou_vax_survey_control_totals.html","id":null,"dir":"Reference","previous_headings":"","what":"Control totals for the Louisville Vaccination Survey — lou_vax_survey_control_totals","title":"Control totals for the Louisville Vaccination Survey — lou_vax_survey_control_totals","text":"Control totals use raking post-stratification Louisville Vaccination Survey data. Control totals population size estimates ACS 2015-2019 5-year Public Use Microdata Sample (PUMS) specific demographic categories among adults Jefferson County, KY. data created using simulation.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/lou_vax_survey_control_totals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control totals for the Louisville Vaccination Survey — lou_vax_survey_control_totals","text":"","code":"data(lou_vax_survey_control_totals)"},{"path":"https://bschneidr.github.io/svrep/reference/lou_vax_survey_control_totals.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Control totals for the Louisville Vaccination Survey — lou_vax_survey_control_totals","text":"nested list object two lists, poststratification raking, contains two elements: estimates variance-covariance. poststratification Control totals combination   RACE_ETHNICITY, SEX, EDUC_ATTAINMENT. estimates: numeric vector estimated population totals. variance-covariance: variance-covariance matrix estimated population totals.  raking Separate control totals   RACE_ETHNICITY, SEX, EDUC_ATTAINMENT. estimates: numeric vector estimated population totals. variance-covariance: variance-covariance matrix estimated population totals.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/redistribute_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Redistribute weight from one group to another — redistribute_weights","title":"Redistribute weight from one group to another — redistribute_weights","text":"Redistributes weight one group another: example, non-respondents respondents. Redistribution conducted full-sample weights well set replicate weights. can done separately combination set grouping variables, example implement nonresponse weighting class adjustment.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/redistribute_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Redistribute weight from one group to another — redistribute_weights","text":"","code":"redistribute_weights(design, reduce_if, increase_if, by)"},{"path":"https://bschneidr.github.io/svrep/reference/redistribute_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Redistribute weight from one group to another — redistribute_weights","text":"design survey design object, created either survey srvyr packages. reduce_if expression indicating cases weights set zero. Must evaluate logical vector values TRUE FALSE. increase_if expression indicating cases weights increased. Must evaluate logical vector values TRUE FALSE. (Optional) character vector names variables used group redistribution weights. example, data include variables named \"stratum\" \"wt_class\", one specify = c(\"stratum\", \"wt_class\").","code":""},{"path":"https://bschneidr.github.io/svrep/reference/redistribute_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Redistribute weight from one group to another — redistribute_weights","text":"survey design object, updated full-sample weights updated replicate weights. resulting survey design object always value combined.weights set TRUE.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/redistribute_weights.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Redistribute weight from one group to another — redistribute_weights","text":"See Chapter 2 Heeringa, West, Berglund (2017) Chapter 13 Valliant, Dever, Kreuter (2018) overview nonresponse adjustment methods based redistributing weights. - Heeringa, S., West, B., Berglund, P. (2017). Applied Survey Data Analysis, 2nd edition. Boca Raton, FL: CRC Press. \"Applied Survey Data Analysis, 2nd edition.\" Boca Raton, FL: CRC Press. - Valliant, R., Dever, J., Kreuter, F. (2018).  \"Practical Tools Designing Weighting Survey Samples, 2nd edition.\" New York: Springer.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/redistribute_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Redistribute weight from one group to another — redistribute_weights","text":"","code":"# Load example data suppressPackageStartupMessages(library(survey)) data(api)  dclus1 <- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc) dclus1$variables$response_status <- sample(x = c(\"Respondent\", \"Nonrespondent\",                                                  \"Ineligible\", \"Unknown eligibility\"),                                            size = nrow(dclus1),                                            replace = TRUE) rep_design <- as.svrepdesign(dclus1)  # Adjust weights for cases with unknown eligibility ue_adjusted_design <- redistribute_weights(     design = rep_design,     reduce_if = response_status %in% c(\"Unknown eligibility\"),     increase_if = !response_status %in% c(\"Unknown eligibility\"),     by = c(\"stype\") )  # Adjust weights for nonresponse nr_adjusted_design <- redistribute_weights(     design = ue_adjusted_design,     reduce_if = response_status %in% c(\"Nonrespondent\"),     increase_if = response_status == \"Respondent\",     by = c(\"stype\") )"},{"path":"https://bschneidr.github.io/svrep/reference/shift_weight.html","id":null,"dir":"Reference","previous_headings":"","what":"(Internal function) Shift weight from one set of cases to another — shift_weight","title":"(Internal function) Shift weight from one set of cases to another — shift_weight","text":"likely want use redistribute_weights instead. function shift_weight internal package used \"--hood.\"","code":""},{"path":"https://bschneidr.github.io/svrep/reference/shift_weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Internal function) Shift weight from one set of cases to another — shift_weight","text":"","code":"shift_weight(wt_set, is_upweight_case, is_downweight_case)"},{"path":"https://bschneidr.github.io/svrep/reference/shift_weight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Internal function) Shift weight from one set of cases to another — shift_weight","text":"wt_set numeric vector weights is_upweight_case logical vector indicating cases whose weight increased is_downweight_case logical vector indicating cases whose weight decreased","code":""},{"path":"https://bschneidr.github.io/svrep/reference/shift_weight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Internal function) Shift weight from one set of cases to another — shift_weight","text":"numeric vector adjusted weights, length wt_set.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/stack_replicate_designs.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack replicate designs, combining data and weights into a single object — stack_replicate_designs","title":"Stack replicate designs, combining data and weights into a single object — stack_replicate_designs","text":"Stack replicate designs: combine rows data, rows replicate weights, respective full-sample weights. can useful comparing estimates set adjustments made weights. Another delicate application combining sets replicate weights multiple years data survey, although must done carefully based guidance data provider.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/stack_replicate_designs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack replicate designs, combining data and weights into a single object — stack_replicate_designs","text":"","code":"stack_replicate_designs(..., .id = \"Design_Name\")"},{"path":"https://bschneidr.github.io/svrep/reference/stack_replicate_designs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack replicate designs, combining data and weights into a single object — stack_replicate_designs","text":"... Replicate-weights survey design objects combine. can supplied one two ways. Option 1 - series design objects, example 'adjusted' = adjusted_design, 'orig' = orig_design. Option 2 - list object containing design objects, example  list('nr' = nr_adjusted_design, 'ue' = ue_adjusted_design). objects must specifications type, rho, mse, scales, rscales. .id single character value, becomes name new column identifiers created output data link row design taken.  labels used identifiers taken named arguments.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/stack_replicate_designs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack replicate designs, combining data and weights into a single object — stack_replicate_designs","text":"replicate-weights survey design object, class svyrep.design svyrep.stacked. resulting survey design object always value combined.weights set TRUE.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/stack_replicate_designs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stack replicate designs, combining data and weights into a single object — stack_replicate_designs","text":"","code":"# Load example data, creating a replicate design object suppressPackageStartupMessages(library(survey)) data(api)  dclus1 <- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc) dclus1$variables$response_status <- sample(x = c(\"Respondent\", \"Nonrespondent\",                                                  \"Ineligible\", \"Unknown eligibility\"),                                            size = nrow(dclus1),                                            replace = TRUE) orig_rep_design <- as.svrepdesign(dclus1)  # Adjust weights for cases with unknown eligibility ue_adjusted_design <- redistribute_weights(     design = orig_rep_design,     reduce_if = response_status %in% c(\"Unknown eligibility\"),     increase_if = !response_status %in% c(\"Unknown eligibility\"),     by = c(\"stype\") )  # Adjust weights for nonresponse nr_adjusted_design <- redistribute_weights(     design = ue_adjusted_design,     reduce_if = response_status %in% c(\"Nonrespondent\"),     increase_if = response_status == \"Respondent\",     by = c(\"stype\") )  # Stack the three designs, using any of the following syntax options stacked_design <- stack_replicate_designs(orig_rep_design, ue_adjusted_design, nr_adjusted_design,                                           .id = \"which_design\") stacked_design <- stack_replicate_designs('original' = orig_rep_design,                                           'unknown eligibility adjusted' = ue_adjusted_design,                                           'nonresponse adjusted' = nr_adjusted_design,                                           .id = \"which_design\") list_of_designs <- list('original' = orig_rep_design,                         'unknown eligibility adjusted' = ue_adjusted_design,                         'nonresponse adjusted' = nr_adjusted_design) stacked_design <- stack_replicate_designs(list_of_designs, .id = \"which_design\")"},{"path":"https://bschneidr.github.io/svrep/reference/summarize_rep_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize the replicate weights — summarize_rep_weights","title":"Summarize the replicate weights — summarize_rep_weights","text":"Summarize replicate weights design","code":""},{"path":"https://bschneidr.github.io/svrep/reference/summarize_rep_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize the replicate weights — summarize_rep_weights","text":"","code":"summarize_rep_weights(rep_design, type = \"both\", by)"},{"path":"https://bschneidr.github.io/svrep/reference/summarize_rep_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize the replicate weights — summarize_rep_weights","text":"rep_design replicate design object, created either survey srvyr packages. type Default \"\". Use type = \"overall\", overall summary replicate weights. Use type = \"specific\" summary column replicate weights, column replicate weights summarized given row summary.  Use type = \"\" list containing summaries, list containing names \"overall\" \"\". (Optional) character vector names variables used group summaries.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/summarize_rep_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize the replicate weights — summarize_rep_weights","text":"type = \"\" (default), result list data frames names \"overall\" \"specific\". type = \"overall\", result data frame providing overall summary replicate weights.  contents \"overall\" summary following: \"nrows\": Number rows weights \"ncols\": Number columns replicate weights \"degf_svy_pkg\": degrees freedom according survey package R \"rank\": matrix rank determined QR decomposition \"avg_wgt_sum\": average column sum \"sd_wgt_sums\": standard deviation column sums \"min_rep_wgt\": minimum value replicate weight \"max_rep_wgt\": maximum value replicate weight type = \"specific\", result data frame providing summary column replicate weights, column replicate weights described given row data frame. contents \"specific\" summary following: \"Rep_Column\": name given column replicate weights.   columns unnamed, column number used instead \"N\": number entries \"N_NONZERO\": number nonzero entries \"SUM\": sum weights \"MEAN\": average weights \"CV\": coefficient variation weights (standard deviation divided mean) \"MIN\": minimum weight \"MAX\": maximum weight","code":""},{"path":"https://bschneidr.github.io/svrep/reference/summarize_rep_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize the replicate weights — summarize_rep_weights","text":"","code":"# Load example data suppressPackageStartupMessages(library(survey)) data(api)  dclus1 <- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc) dclus1$variables$response_status <- sample(x = c(\"Respondent\", \"Nonrespondent\",                                                  \"Ineligible\", \"Unknown eligibility\"),                                            size = nrow(dclus1),                                            replace = TRUE) rep_design <- as.svrepdesign(dclus1)  # Adjust weights for cases with unknown eligibility ue_adjusted_design <- redistribute_weights(     design = rep_design,     reduce_if = response_status %in% c(\"Unknown eligibility\"),     increase_if = !response_status %in% c(\"Unknown eligibility\"),     by = c(\"stype\") )  # Summarize replicate weights  summarize_rep_weights(rep_design, type = \"both\") #> $overall #>   nrows ncols degf_svy_pkg rank avg_wgt_sum sd_wgt_sums min_rep_wgt max_rep_wgt #> 1   183    15           14   15        6194    403.1741           0    36.26464 #>  #> $specific #>    Rep_Column   N N_NONZERO      SUM     MEAN         CV MIN      MAX #> 1           1 183       172 6237.518 34.08480 0.25358407   0 36.26464 #> 2           2 183       179 6491.370 35.47197 0.14989713   0 36.26464 #> 3           3 183       181 6563.900 35.86830 0.10540606   0 36.26464 #> 4           4 183       170 6164.989 33.68846 0.27729183   0 36.26464 #> 5           5 183       181 6563.900 35.86830 0.10540606   0 36.26464 #> 6           6 183       179 6491.370 35.47197 0.14989713   0 36.26464 #> 7           7 183       179 6491.370 35.47197 0.14989713   0 36.26464 #> 8           8 183       167 6056.195 33.09396 0.31037848   0 36.26464 #> 9           9 183       174 6310.047 34.48113 0.22805336   0 36.26464 #> 10         10 183       149 5403.431 29.52695 0.47900073   0 36.26464 #> 11         11 183       162 5874.872 32.10312 0.36102892   0 36.26464 #> 12         12 183       146 5294.637 28.93244 0.50479412   0 36.26464 #> 13         13 183       170 6164.989 33.68846 0.27729183   0 36.26464 #> 14         14 183       182 6600.164 36.06647 0.07432829   0 36.26464 #> 15         15 183       171 6201.253 33.88663 0.26563324   0 36.26464 #>   # Summarize replicate weights by grouping variables  summarize_rep_weights(ue_adjusted_design, type = 'overall',                       by = c(\"response_status\")) #>       response_status nrows ncols degf_svy_pkg rank avg_wgt_sum sd_wgt_sums #> 1          Ineligible    35    15           13   14    1799.445    135.9468 #> 2       Nonrespondent    42    15           14   15    2107.176    168.3374 #> 3          Respondent    45    15           14   15    2287.379    155.3171 #> 4 Unknown eligibility    61    15           -1    0       0.000      0.0000 #>   min_rep_wgt max_rep_wgt #> 1           0    72.52928 #> 2           0    72.52928 #> 3           0    72.52928 #> 4           0     0.00000  summarize_rep_weights(ue_adjusted_design, type = 'overall',                       by = c(\"stype\", \"response_status\")) #>    stype     response_status nrows ncols degf_svy_pkg rank avg_wgt_sum #> 1      E          Ineligible    26    15           10   11  1280.21875 #> 2      H          Ineligible     4    15            2    3   237.44704 #> 3      M          Ineligible     5    15            2    3   281.77934 #> 4      E       Nonrespondent    37    15           12   13  1821.52494 #> 5      H       Nonrespondent     1    15            0    1    59.36176 #> 6      M       Nonrespondent     4    15            3    4   226.28958 #> 7      E          Respondent    36    15           11   12  1772.22378 #> 8      H          Respondent     3    15            1    2   177.04915 #> 9      M          Respondent     6    15            3    4   338.10599 #> 10     E Unknown eligibility    45    15           -1    0     0.00000 #> 11     H Unknown eligibility     6    15           -1    0     0.00000 #> 12     M Unknown eligibility    10    15           -1    0     0.00000 #>    sd_wgt_sums min_rep_wgt max_rep_wgt #> 1    117.60192           0    53.99402 #> 2     37.69885           0    72.52928 #> 3     41.19343           0    66.48517 #> 4    155.27778           0    53.99402 #> 5     17.02586           0    72.52928 #> 6     30.37309           0    66.48517 #> 7    143.23893           0    53.99402 #> 8     32.16082           0    72.52928 #> 9     47.17701           0    66.48517 #> 10     0.00000           0     0.00000 #> 11     0.00000           0     0.00000 #> 12     0.00000           0     0.00000  # Compare replicate weights  rep_wt_summaries <- lapply(list('original' = rep_design,                                 'adjusted' = ue_adjusted_design),                            summarize_rep_weights,                            type = \"overall\") print(rep_wt_summaries) #> $original #>   nrows ncols degf_svy_pkg rank avg_wgt_sum sd_wgt_sums min_rep_wgt max_rep_wgt #> 1   183    15           14   15        6194    403.1741           0    36.26464 #>  #> $adjusted #>   nrows ncols degf_svy_pkg rank avg_wgt_sum sd_wgt_sums min_rep_wgt max_rep_wgt #> 1   183    15           14   15        6194    403.1741           0    72.52928 #>"},{"path":"https://bschneidr.github.io/svrep/reference/svrep-package.html","id":null,"dir":"Reference","previous_headings":"","what":"svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights — svrep-package","title":"svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights — svrep-package","text":"Provides tools creating working survey replicate weights, extending functionality 'survey' package Lumley (2004) doi:10.18637/jss.v009.i08 . Methods provided applying nonresponse adjustments full-sample replicate weights suggested Rust Rao (1996) doi:10.1177/096228029600500305 . Implements methods sample-based calibration described Opsomer Erciulescu (2021) https://www150.statcan.gc.ca/n1/pub/12-001-x/2021002/article/00006-eng.htm. Diagnostic functions included compare weights weighted estimates different sets replicate weights.","code":""},{"path":[]},{"path":"https://bschneidr.github.io/svrep/reference/svrep-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights — svrep-package","text":"Maintainer: Ben Schneider benjamin.julius.schneider@gmail.com (ORCID)","code":""},{"path":"https://bschneidr.github.io/svrep/reference/svyby_repwts.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare survey statistics calculated separately from different sets of replicate weights — svyby_repwts","title":"Compare survey statistics calculated separately from different sets of replicate weights — svyby_repwts","text":"modified version svyby() function survey package. Whereas svyby() calculates statistics separately subset formed specified grouping variable, svyby_repwts() calculates statistics separately replicate design, addition additional user-specified grouping variables.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/svyby_repwts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare survey statistics calculated separately from different sets of replicate weights — svyby_repwts","text":"","code":"svyby_repwts(   rep_designs,   formula,   by,   FUN,   ...,   deff = FALSE,   keep.var = TRUE,   keep.names = TRUE,   verbose = FALSE,   vartype = c(\"se\", \"ci\", \"ci\", \"cv\", \"cvpct\", \"var\"),   drop.empty.groups = TRUE,   return.replicates = FALSE,   na.rm.by = FALSE,   na.rm.all = FALSE,   multicore = getOption(\"survey.multicore\") )"},{"path":"https://bschneidr.github.io/svrep/reference/svyby_repwts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare survey statistics calculated separately from different sets of replicate weights — svyby_repwts","text":"rep_designs replicate-weights survey designs compared. Supplied either : named list replicate-weights survey design objects, example list('nr' = nr_adjusted_design, 'ue' = ue_adjusted_design). 'stacked' replicate-weights survey design object created stack_replicate_designs(). designs must number columns replicate weights, type (bootstrap, JKn, etc.) formula formula specifying variables pass FUN formula specifying factors define subsets FUN function taking formula survey design object first two arguments. Usually function survey package, svytotal svymean. ... arguments FUN deff value TRUE FALSE, indicating whether design effects estimated possible. keep.var value TRUE FALSE. FUN returns svystat object, indicates whether extract standard errors . keep.names Define row names based subsets verbose TRUE, print label subset processed. vartype Report variability one standard error, confidence interval, coefficient variation,  percent coefficient variation, variance drop.empty.groups FALSE, report NA empty groups, TRUE drop output return.replicates TRUE, return replicates \"replicates\" attribute result. can useful want produce custom summaries estimates replicate. na.rm.true, omit groups defined NA values variables na.rm.true, check groups non-missing observations variables defined formula treat groups empty multicore Use multicore package distribute subsets multiple processors?","code":""},{"path":"https://bschneidr.github.io/svrep/reference/svyby_repwts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare survey statistics calculated separately from different sets of replicate weights — svyby_repwts","text":"object class \"svyby\": data frame showing grouping factors results FUN combination grouping factors. first grouping factor always consists indicators replicate design used estimate.","code":""},{"path":"https://bschneidr.github.io/svrep/reference/svyby_repwts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare survey statistics calculated separately from different sets of replicate weights — svyby_repwts","text":"","code":"suppressPackageStartupMessages(library(survey)) data(api)  dclus1 <- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc) dclus1$variables$response_status <- sample(x = c(\"Respondent\", \"Nonrespondent\",                                                  \"Ineligible\", \"Unknown eligibility\"),                                            size = nrow(dclus1),                                            replace = TRUE) orig_rep_design <- as.svrepdesign(dclus1)  # Adjust weights for cases with unknown eligibility ue_adjusted_design <- redistribute_weights(     design = orig_rep_design,     reduce_if = response_status %in% c(\"Unknown eligibility\"),     increase_if = !response_status %in% c(\"Unknown eligibility\"),     by = c(\"stype\") )  # Adjust weights for nonresponse nr_adjusted_design <- redistribute_weights(     design = ue_adjusted_design,     reduce_if = response_status %in% c(\"Nonrespondent\"),     increase_if = response_status == \"Respondent\",     by = c(\"stype\") )  # Compare estimates from the three sets of replicate weights    list_of_designs <- list('original' = orig_rep_design,                           'unknown eligibility adjusted' = ue_adjusted_design,                           'nonresponse adjusted' = nr_adjusted_design)    ##_ First compare overall means for two variables   means_by_design <- svyby_repwts(formula = ~ api00 + api99,                                   FUN = svymean,                                   rep_design = list_of_designs)    print(means_by_design) #>                                               Design_Name    api00    api99 #> nonresponse adjusted                 nonresponse adjusted 644.9859 605.8247 #> original                                         original 644.1694 606.9781 #> unknown eligibility adjusted unknown eligibility adjusted 647.1747 608.0538 #>                                   se1      se2 #> nonresponse adjusted         28.58723 29.71602 #> original                     26.32936 26.99854 #> unknown eligibility adjusted 22.20461 23.29581    ##_ Next compare domain means for two variables   domain_means_by_design <- svyby_repwts(formula = ~ api00 + api99,                                          by = ~ stype,                                          FUN = svymean,                                          rep_design = list_of_designs)    print(domain_means_by_design) #>                                                 Design_Name stype    api00 #> nonresponse adjusted.E                 nonresponse adjusted     E 645.9485 #> original.E                                         original     E 648.8681 #> unknown eligibility adjusted.E unknown eligibility adjusted     E 649.9608 #> nonresponse adjusted.H                 nonresponse adjusted     H 645.8667 #> original.H                                         original     H 618.5714 #> unknown eligibility adjusted.H unknown eligibility adjusted     H 629.0000 #> nonresponse adjusted.M                 nonresponse adjusted     M 638.9478 #> original.M                                         original     M 631.4400 #> unknown eligibility adjusted.M unknown eligibility adjusted     M 641.3043 #>                                   api99      se1      se2 #> nonresponse adjusted.E         601.5812 30.18993 31.51494 #> original.E                     607.7917 25.37430 25.83542 #> unknown eligibility adjusted.E 606.3725 22.78838 24.02373 #> nonresponse adjusted.H         626.5667 33.11578 41.71329 #> original.H                     595.7143 46.34412 50.75106 #> unknown eligibility adjusted.H 605.8000 42.36171 47.70114 #> nonresponse adjusted.M         618.6522 30.71516 30.74076 #> original.M                     608.6000 33.68762 34.82521 #> unknown eligibility adjusted.M 619.0000 28.58553 29.01539  # Calculate confidence interval for difference between estimates  ests_by_design <- svyby_repwts(rep_designs = list('NR-adjusted' = nr_adjusted_design,                                                   'Original' = orig_rep_design),                                FUN = svymean, formula = ~ api00 + api99)  differences_in_estimates <- svycontrast(stat = ests_by_design, contrasts = list(   'Mean of api00: NR-adjusted vs. Original' = c(1,-1,0,0),   'Mean of api99: NR-adjusted vs. Original' = c(0,0,1,-1) ))  print(differences_in_estimates) #>                                         contrast     SE #> Mean of api00: NR-adjusted vs. Original  0.81649 7.2804 #> Mean of api99: NR-adjusted vs. Original -1.15339 7.6535  confint(differences_in_estimates, level = 0.95) #>                                             2.5 %   97.5 % #> Mean of api00: NR-adjusted vs. Original -13.45281 15.08578 #> Mean of api99: NR-adjusted vs. Original -16.15400 13.84721"},{"path":"https://bschneidr.github.io/svrep/news/index.html","id":"svrep-development-version","dir":"Changelog","previous_headings":"","what":"svrep (development version)","title":"svrep (development version)","text":"using as_data_frame_with_weights(), ensure full-sample weight named \"FULL_SAMPLE_WGT\" user specify something different. calibrate_to_estimate(), ensure output names list columns perturbed control columns col_selection instead perturbed_control_cols, name matches corresponding function argument, col_selection. Improvements documentation (formatting tweaks typo fixes)","code":""},{"path":"https://bschneidr.github.io/svrep/news/index.html","id":"svrep-030","dir":"Changelog","previous_headings":"","what":"svrep 0.3.0","title":"svrep 0.3.0","text":"CRAN release: 2022-07-05 Added helper function as_data_frame_with_weights() convert survey design object data frame columns weights (full-sample weights , applicable, replicate weights). useful saving data weights data file. Added argument summarize_rep_weights() allows specification one grouping variables use summaries (e.g. = c('stratum', 'response_status') can used summarize response status within stratum). Added small vignette “Nonresponse Adjustments” illustrate conduct nonresponse adjustments using redistribute_weights(). Minor Updates Bug Fixes: Internal code update avoid annoying harmless warning message rho calibrate_to_estimate(). Bug fix stack_replicate_designs() designs created .svrepdesign(..., type = 'mrbbootstrap') .svrepdesign(..., type = 'subbootstrap') threw error.","code":""},{"path":"https://bschneidr.github.io/svrep/news/index.html","id":"svrep-020","dir":"Changelog","previous_headings":"","what":"svrep 0.2.0","title":"svrep 0.2.0","text":"CRAN release: 2022-05-12 Added functions calibrate_to_estimate() calibrate_to_sample() calibrating estimated control totals methods account sampling variance control totals. overview functions, please see new vignette “Calibrating Estimated Control Totals”. function calibrate_to_estimate() requires user supply vector control totals variance-covariance matrix. function applies Fuller’s proposed adjustments replicate weights, control totals varied across replicates perturbing control totals using spectral decomposition control totals’ variance-covariance matrix. function calibrate_to_sample() requires user supply replicate design primary survey interest well replicate design control survey used estimate control totals calibration. function applies Opsomer & Erciulescu’s method varying control totals across replicates primary survey matching primary survey replicate replicate control survey. Added example dataset, lou_vax_survey, simulated survey measuring Covid-19 vaccination status handful demographic variables, based simple random sample 1,000 residents Louisville, Kentucky approximately 50% response rate. accompanying dataset lou_pums_microdata provides person-level microdata American Community Survey (ACS) 2015-2019 public-use microdata sample (PUMS) data Louisville, KY. dataset lou_pums_microdata includes replicate weights use variance estimation can used generate control totals lou_vax_survey.","code":""},{"path":"https://bschneidr.github.io/svrep/news/index.html","id":"svrep-010","dir":"Changelog","previous_headings":"","what":"svrep 0.1.0","title":"svrep 0.1.0","text":"CRAN release: 2022-03-30 Initial release package.","code":""}]
